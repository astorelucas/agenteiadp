{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "81925204",
   "metadata": {},
   "source": [
    "## Testando Prompt (usando create_pandas_dataframe_agent)\n",
    "Observações: aqui o prompt já é pre-made, portanto para alterar ele devo adicionar prefixo e/ou sufixo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f09fdef3",
   "metadata": {},
   "source": [
    "### Tokens e imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "43d8ff2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# default\n",
    "import os\n",
    "from getpass import getpass\n",
    "import pandas as pd\n",
    "from typing import Annotated\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "# langchain \n",
    "from langgraph.graph.message import add_messages\n",
    "from langchain.agents import tool\n",
    "from langgraph.graph import StateGraph, START, END, MessagesState\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langchain.tools.render import render_text_description\n",
    "\n",
    "from langchain_community.chat_models import ChatDeepInfra\n",
    "from langchain_tavily import TavilySearch\n",
    "\n",
    "\n",
    "from langchain_core.messages import HumanMessage, SystemMessage, AIMessage\n",
    "from langchain_core.prompts import ChatPromptTemplate, PromptTemplate\n",
    "from langchain_core.prompts import HumanMessagePromptTemplate\n",
    "\n",
    "from langchain_experimental.agents.agent_toolkits import create_pandas_dataframe_agent\n",
    "\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from pydantic import BaseModel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6029158f",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"DEEPINFRA_API_TOKEN\"] = getpass(\"Digite sua chave da DeepInfra: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "43e569a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"TAVILY_API_KEY\"] = getpass(\"Digite sua chave do Travily: \")\n",
    "#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"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05063302",
   "metadata": {},
   "source": [
    "### Definindo Tools\n",
    "Aqui definirei as tools do meu agente. Estou responsável por colocar tools relacionadas a imputação de valores.\n",
    "Irei colocar algumas opções e tentar explicar as características de cada uma, para que o agente decida qual o melhor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f4a4088",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame carregado: 26208 linhas, 359 colunas.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from langchain_core.tools import tool\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "# Carrega o DataFrame global\n",
    "df = pd.read_csv(\"./datasets/teste_com_nulos.csv\")\n",
    "print(f\"DataFrame carregado: {df.shape[0]} linhas, {df.shape[1]} colunas.\")\n",
    "\n",
    "@tool()\n",
    "def imputacao_mice() -> str:\n",
    "    \"\"\"\n",
    "    **MICE (IterativeImputer com RandomForest)**  \n",
    "    **Uso ideal**:  \n",
    "    - Dados com relações lineares/moderadamente não-lineares.  \n",
    "    - Missing Data Aleatório (MAR).  \n",
    "    - Até 100k linhas.  \n",
    "\n",
    "    **Exemplo**: Planilhas financeiras (PIB, inflação).  \n",
    "\n",
    "    **Custo**: Médio.  \n",
    "\n",
    "    **Como age**:  \n",
    "    1. Adiciona lags temporais automaticamente.  \n",
    "    2. Usa Florestas Aleatórias para imputação iterativa.  \n",
    "    \"\"\"\n",
    "    global df\n",
    "    for col in df.select_dtypes(include=['number']).columns:\n",
    "        df[f'{col}_lag1'] = df[col].shift(1)\n",
    "    \n",
    "    imputer = IterativeImputer(\n",
    "        estimator=RandomForestRegressor(n_estimators=10),\n",
    "        random_state=0\n",
    "    )\n",
    "    df.iloc[:, :] = imputer.fit_transform(df)\n",
    "    return \"MICE aplicado. Relações entre colunas consideradas.\"\n",
    "\n",
    "@tool()\n",
    "def imputacao_missforest() -> str:\n",
    "    \"\"\"\n",
    "    **MissForest Modernizado (RandomForest)**  \n",
    "    **Uso ideal**:  \n",
    "    - Dados não-lineares com outliers.  \n",
    "    - Quando MICE falha em capturar padrões complexos.  \n",
    "\n",
    "    **Exemplo**: Dados médicos (exames com interações não óbvias).  \n",
    "\n",
    "    **Custo**: Alto.  \n",
    "\n",
    "    **Como age**:  \n",
    "    1. Adiciona médias móveis para contexto temporal.  \n",
    "    2. Usa RandomForest para imputação robusta.  \n",
    "    \"\"\"\n",
    "    global df\n",
    "    for col in df.select_dtypes(include=['number']).columns:\n",
    "        df[f'{col}_rolling_avg'] = df[col].rolling(window=3, min_periods=1).mean()\n",
    "\n",
    "    imputer = IterativeImputer(\n",
    "        estimator=RandomForestRegressor(n_estimators=100),\n",
    "        max_iter=20,\n",
    "        random_state=42\n",
    "    )\n",
    "    df.iloc[:, :] = imputer.fit_transform(df)\n",
    "    return \"MissForest aplicado. Não-linearidades tratadas.\"\n",
    "\n",
    "@tool()\n",
    "def imputacao_stmw() -> str:\n",
    "    \"\"\"\n",
    "    **STMW (MissForest + Pesos Temporais)**  \n",
    "    **Uso ideal**:  \n",
    "    - Séries temporais multivariadas.  \n",
    "    - Dados onde valores recentes são mais relevantes.  \n",
    "\n",
    "    **Exemplo**: Sensores IoT (temperatura, umidade ao longo do tempo).  \n",
    "\n",
    "    **Custo**: Alto.  \n",
    "\n",
    "    **Como age**:  \n",
    "    1. Aplica decay exponencial para ponderar observações recentes.  \n",
    "    2. Combina com médias móveis e tendências.  \n",
    "    \"\"\"\n",
    "    global df\n",
    "    time_weights = np.exp(-0.1 * np.arange(len(df)))[::-1]\n",
    "    \n",
    "    for col in df.select_dtypes(include=['number']).columns:\n",
    "        df[f'{col}_trend'] = df[col].rolling(window=5).mean()\n",
    "    \n",
    "    imputer = IterativeImputer(\n",
    "        estimator=RandomForestRegressor(n_estimators=100),\n",
    "        max_iter=15,\n",
    "        random_state=42\n",
    "    )\n",
    "    df.iloc[:, :] = imputer.fit_transform(df, sample_weight=time_weights)\n",
    "    return \"STMW aplicado. Temporalidade ponderada.\"\n",
    "\n",
    "@tool()\n",
    "def imputacao_gain() -> str:\n",
    "    \"\"\"\n",
    "    **GAIN Simplificado (MLPRegressor)**  \n",
    "    **Uso ideal**:  \n",
    "    - Big Data com padrões complexos.  \n",
    "    - Quando outros métodos falham.  \n",
    "\n",
    "    **Exemplo**: Dados genômicos ou imagens médicas.  \n",
    "\n",
    "    **Custo**: Muito alto.  \n",
    "\n",
    "    **Como age**:  \n",
    "    1. Usa redes neurais para imputação generativa.  \n",
    "    2. Captura padrões não-lineares profundos.  \n",
    "    \"\"\"\n",
    "    global df\n",
    "    imputer = IterativeImputer(\n",
    "        estimator=MLPRegressor(hidden_layer_sizes=(128,)),\n",
    "        max_iter=50,\n",
    "        random_state=42\n",
    "    )\n",
    "    df.iloc[:, :] = imputer.fit_transform(df)\n",
    "    return \"GAIN simplificado aplicado. Padrões complexos modelados.\"\n",
    "\n",
    "\n",
    "# Ferramentas Auxiliares\n",
    "@tool()\n",
    "def salvar_resultados() -> str:\n",
    "    \"\"\"Salva o DataFrame imputado em um novo arquivo CSV para salvar as mudanças feitas.\"\"\"\n",
    "    global df\n",
    "    df.to_csv(\"./datasets/teste_imputado.csv\", index=False)\n",
    "    return \"DataFrame salvo como 'teste_imputado.csv'.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f01b5f8",
   "metadata": {},
   "source": [
    "## Fazendo as tools que usam Colunas\n",
    "\n",
    "Vou pegar (dentro delas) uma lista de colunas com valores nulos, e rodar loop pra imputar pra cada coluna da lista"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "bf7acd74",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nulls = df.copy().drop('timestamp', axis=1).select_dtypes(include='number')\n",
    "null_columns = df_nulls.columns[df_nulls.isna().any()]\n",
    "\n",
    "# for column in  null_columns:\n",
    "#     print(column)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10147c6a",
   "metadata": {},
   "source": [
    "agora vou tentar criar o K-Nearest Neighbors usando essa lista"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "5a638bcf",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[61]\u001b[39m\u001b[32m, line 24\u001b[39m\n\u001b[32m     18\u001b[39m     df_filled = pd.DataFrame(imputer.fit_transform(df_nulls),\n\u001b[32m     19\u001b[39m                              columns=df_nulls.columns,\n\u001b[32m     20\u001b[39m                              index=df_nulls.index)    \n\u001b[32m     22\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m df.combine_first(df_filled)\n\u001b[32m---> \u001b[39m\u001b[32m24\u001b[39m newdf = \u001b[43mimputation_k_nearest_neighbors\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m3\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[61]\u001b[39m\u001b[32m, line 18\u001b[39m, in \u001b[36mimputation_k_nearest_neighbors\u001b[39m\u001b[34m(k)\u001b[39m\n\u001b[32m     16\u001b[39m \u001b[38;5;28;01mglobal\u001b[39;00m df\n\u001b[32m     17\u001b[39m imputer = KNNImputer(n_neighbors=k)\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m df_filled = pd.DataFrame(\u001b[43mimputer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_nulls\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[32m     19\u001b[39m                          columns=df_nulls.columns,\n\u001b[32m     20\u001b[39m                          index=df_nulls.index)    \n\u001b[32m     22\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m df.combine_first(df_filled)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\gabri\\Documents\\agenteiadp\\.venv\\Lib\\site-packages\\sklearn\\utils\\_set_output.py:316\u001b[39m, in \u001b[36m_wrap_method_output.<locals>.wrapped\u001b[39m\u001b[34m(self, X, *args, **kwargs)\u001b[39m\n\u001b[32m    314\u001b[39m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[32m    315\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, *args, **kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m316\u001b[39m     data_to_wrap = \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    317\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[32m    318\u001b[39m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[32m    319\u001b[39m         return_tuple = (\n\u001b[32m    320\u001b[39m             _wrap_data_with_container(method, data_to_wrap[\u001b[32m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[32m    321\u001b[39m             *data_to_wrap[\u001b[32m1\u001b[39m:],\n\u001b[32m    322\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\gabri\\Documents\\agenteiadp\\.venv\\Lib\\site-packages\\sklearn\\base.py:892\u001b[39m, in \u001b[36mTransformerMixin.fit_transform\u001b[39m\u001b[34m(self, X, y, **fit_params)\u001b[39m\n\u001b[32m    877\u001b[39m         warnings.warn(\n\u001b[32m    878\u001b[39m             (\n\u001b[32m    879\u001b[39m                 \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mThis object (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m) has a `transform`\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m    887\u001b[39m             \u001b[38;5;167;01mUserWarning\u001b[39;00m,\n\u001b[32m    888\u001b[39m         )\n\u001b[32m    890\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    891\u001b[39m     \u001b[38;5;66;03m# fit method of arity 1 (unsupervised transformation)\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m892\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    893\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    894\u001b[39m     \u001b[38;5;66;03m# fit method of arity 2 (supervised transformation)\u001b[39;00m\n\u001b[32m    895\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.fit(X, y, **fit_params).transform(X)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\gabri\\Documents\\agenteiadp\\.venv\\Lib\\site-packages\\sklearn\\utils\\_set_output.py:316\u001b[39m, in \u001b[36m_wrap_method_output.<locals>.wrapped\u001b[39m\u001b[34m(self, X, *args, **kwargs)\u001b[39m\n\u001b[32m    314\u001b[39m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[32m    315\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, *args, **kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m316\u001b[39m     data_to_wrap = \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    317\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[32m    318\u001b[39m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[32m    319\u001b[39m         return_tuple = (\n\u001b[32m    320\u001b[39m             _wrap_data_with_container(method, data_to_wrap[\u001b[32m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[32m    321\u001b[39m             *data_to_wrap[\u001b[32m1\u001b[39m:],\n\u001b[32m    322\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\gabri\\Documents\\agenteiadp\\.venv\\Lib\\site-packages\\sklearn\\impute\\_knn.py:376\u001b[39m, in \u001b[36mKNNImputer.transform\u001b[39m\u001b[34m(self, X)\u001b[39m\n\u001b[32m    367\u001b[39m \u001b[38;5;66;03m# process in fixed-memory chunks\u001b[39;00m\n\u001b[32m    368\u001b[39m gen = pairwise_distances_chunked(\n\u001b[32m    369\u001b[39m     X[row_missing_idx, :],\n\u001b[32m    370\u001b[39m     \u001b[38;5;28mself\u001b[39m._fit_X,\n\u001b[32m   (...)\u001b[39m\u001b[32m    374\u001b[39m     reduce_func=process_chunk,\n\u001b[32m    375\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m376\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mgen\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    377\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# process_chunk modifies X in place. No return value.\u001b[39;49;00m\n\u001b[32m    378\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mpass\u001b[39;49;00m\n\u001b[32m    380\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.keep_empty_features:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\gabri\\Documents\\agenteiadp\\.venv\\Lib\\site-packages\\sklearn\\metrics\\pairwise.py:2249\u001b[39m, in \u001b[36mpairwise_distances_chunked\u001b[39m\u001b[34m(X, Y, reduce_func, metric, n_jobs, working_memory, **kwds)\u001b[39m\n\u001b[32m   2247\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m reduce_func \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   2248\u001b[39m     chunk_size = D_chunk.shape[\u001b[32m0\u001b[39m]\n\u001b[32m-> \u001b[39m\u001b[32m2249\u001b[39m     D_chunk = \u001b[43mreduce_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mD_chunk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msl\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstart\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2250\u001b[39m     _check_chunk_size(D_chunk, chunk_size)\n\u001b[32m   2251\u001b[39m \u001b[38;5;28;01myield\u001b[39;00m D_chunk\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\gabri\\Documents\\agenteiadp\\.venv\\Lib\\site-packages\\sklearn\\impute\\_knn.py:359\u001b[39m, in \u001b[36mKNNImputer.transform.<locals>.process_chunk\u001b[39m\u001b[34m(dist_chunk, start)\u001b[39m\n\u001b[32m    354\u001b[39m     dist_subset = dist_chunk[dist_idx_map[receivers_idx] - start][\n\u001b[32m    355\u001b[39m         :, potential_donors_idx\n\u001b[32m    356\u001b[39m     ]\n\u001b[32m    358\u001b[39m n_neighbors = \u001b[38;5;28mmin\u001b[39m(\u001b[38;5;28mself\u001b[39m.n_neighbors, \u001b[38;5;28mlen\u001b[39m(potential_donors_idx))\n\u001b[32m--> \u001b[39m\u001b[32m359\u001b[39m value = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_calc_impute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    360\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdist_subset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    361\u001b[39m \u001b[43m    \u001b[49m\u001b[43mn_neighbors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    362\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_fit_X\u001b[49m\u001b[43m[\u001b[49m\u001b[43mpotential_donors_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcol\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    363\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmask_fit_X\u001b[49m\u001b[43m[\u001b[49m\u001b[43mpotential_donors_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcol\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    364\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    365\u001b[39m X[receivers_idx, col] = value\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\gabri\\Documents\\agenteiadp\\.venv\\Lib\\site-packages\\sklearn\\impute\\_knn.py:188\u001b[39m, in \u001b[36mKNNImputer._calc_impute\u001b[39m\u001b[34m(self, dist_pot_donors, n_neighbors, fit_X_col, mask_fit_X_col)\u001b[39m\n\u001b[32m    164\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Helper function to impute a single column.\u001b[39;00m\n\u001b[32m    165\u001b[39m \n\u001b[32m    166\u001b[39m \u001b[33;03mParameters\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    185\u001b[39m \u001b[33;03m    Imputed values for receiver.\u001b[39;00m\n\u001b[32m    186\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    187\u001b[39m \u001b[38;5;66;03m# Get donors\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m188\u001b[39m donors_idx = \u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43margpartition\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdist_pot_donors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_neighbors\u001b[49m\u001b[43m \u001b[49m\u001b[43m-\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m[\n\u001b[32m    189\u001b[39m     :, :n_neighbors\n\u001b[32m    190\u001b[39m ]\n\u001b[32m    192\u001b[39m \u001b[38;5;66;03m# Get weight matrix from distance matrix\u001b[39;00m\n\u001b[32m    193\u001b[39m donors_dist = dist_pot_donors[\n\u001b[32m    194\u001b[39m     np.arange(donors_idx.shape[\u001b[32m0\u001b[39m])[:, \u001b[38;5;28;01mNone\u001b[39;00m], donors_idx\n\u001b[32m    195\u001b[39m ]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\gabri\\Documents\\agenteiadp\\.venv\\Lib\\site-packages\\numpy\\_core\\fromnumeric.py:961\u001b[39m, in \u001b[36margpartition\u001b[39m\u001b[34m(a, kth, axis, kind, order)\u001b[39m\n\u001b[32m    875\u001b[39m \u001b[38;5;129m@array_function_dispatch\u001b[39m(_argpartition_dispatcher)\n\u001b[32m    876\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34margpartition\u001b[39m(a, kth, axis=-\u001b[32m1\u001b[39m, kind=\u001b[33m'\u001b[39m\u001b[33mintroselect\u001b[39m\u001b[33m'\u001b[39m, order=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m    877\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    878\u001b[39m \u001b[33;03m    Perform an indirect partition along the given axis using the\u001b[39;00m\n\u001b[32m    879\u001b[39m \u001b[33;03m    algorithm specified by the `kind` keyword. It returns an array of\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    959\u001b[39m \n\u001b[32m    960\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m961\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_wrapfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43margpartition\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkth\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkind\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkind\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[43m=\u001b[49m\u001b[43morder\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\gabri\\Documents\\agenteiadp\\.venv\\Lib\\site-packages\\numpy\\_core\\fromnumeric.py:57\u001b[39m, in \u001b[36m_wrapfunc\u001b[39m\u001b[34m(obj, method, *args, **kwds)\u001b[39m\n\u001b[32m     54\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _wrapit(obj, method, *args, **kwds)\n\u001b[32m     56\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m57\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbound\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     58\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m     59\u001b[39m     \u001b[38;5;66;03m# A TypeError occurs if the object does have such a method in its\u001b[39;00m\n\u001b[32m     60\u001b[39m     \u001b[38;5;66;03m# class, but its signature is not identical to that of NumPy's. This\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     64\u001b[39m     \u001b[38;5;66;03m# Call _wrapit from within the except clause to ensure a potential\u001b[39;00m\n\u001b[32m     65\u001b[39m     \u001b[38;5;66;03m# exception has a traceback chain.\u001b[39;00m\n\u001b[32m     66\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _wrapit(obj, method, *args, **kwds)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "from sklearn.impute import KNNImputer  \n",
    "\n",
    "#testando com loop\n",
    "# def imputation_k_nearest_neighbors(k):\n",
    "#     global df\n",
    "#     for column in null_columns:\n",
    "#         # Split the data into features (X) and target (y)\n",
    "#         X = df.drop(column, axis=1)\n",
    "#         y = df[column]\n",
    "        \n",
    "#         imputer = KNNImputer(n_neighbors=k)\n",
    "#         df[column] = imputer.fit_transform(df[[column]])\n",
    "\n",
    "# encontrei um KNN multivariado (faz com o dataset todo ao mesmo tempo)\n",
    "def imputation_k_nearest_neighbors(k=5):\n",
    "    global df\n",
    "    imputer = KNNImputer(n_neighbors=k)\n",
    "    df_filled = pd.DataFrame(imputer.fit_transform(df_nulls),\n",
    "                             columns=df_nulls.columns,\n",
    "                             index=df_nulls.index)    \n",
    "    \n",
    "    return df.combine_first(df_filled)\n",
    "\n",
    "newdf = imputation_k_nearest_neighbors(3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "befc29c7",
   "metadata": {},
   "source": [
    "Adicionando as tools e criando o agente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f86c25e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tavily = TavilySearch(max_results=2)\n",
    "\n",
    "tools = [\n",
    "    tavily,\n",
    "    imputacao_mice,\n",
    "    imputacao_missforest,\n",
    "    imputacao_stmw,\n",
    "    imputacao_gain,\n",
    "    salvar_resultados\n",
    "]\n",
    "\n",
    "llm = ChatDeepInfra(model=\"meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8\", temperature=0)\n",
    "agent = create_pandas_dataframe_agent(\n",
    "    llm = llm,\n",
    "    df= pd.DataFrame(df),\n",
    "    verbose=True,\n",
    "    allow_dangerous_code=True,\n",
    "    return_intermediate_steps=True, # Retorna tb os pensamentos e ações do agente\n",
    "    agent_type=\"zero-shot-react-description\",\n",
    "    extra_tools = tools,\n",
    "    max_iterations = 10,\n",
    "    include_df_in_prompt = False,\n",
    "    prefix = \"\"\"\n",
    "        Você é um analista de dados especialista em Análise Exploratória de Dados (EDA), com foco principal em datasets de séries temporais. Sua tarefa é usar as ferramentas disponíveis para extrair insights valiosos e responder às perguntas do usuário.\n",
    "        Você tem acesso a ferramentas de manipulação e análise de dados (pandas), algumas ferramentas extras de manipulação e, crucialmente, uma ferramenta de pesquisa (`tavily`).\n",
    "\n",
    "        Siga estas diretrizes rigorosas para sua análise:\n",
    "    1.  **Compreensão Inicial**: Comece sempre com uma visão geral do dataframe, verificando os tipos de dados, valores ausentes, estatísticas descritivas e as primeiras/últimas linhas para entender a estrutura dos dados.\n",
    "    2.  **Análise de Série Temporal**: Priorize técnicas de EDA específicas para séries temporais. Considere visualizações, decomposição de séries temporais (tendência, sazonalidade, resíduo), autocorrelação (ACF/PACF) e análise de estacionaridade.\n",
    "    3.  **Uso Inteligente de Ferramentas**:\n",
    "        * Utilize as ferramentas para qualquer operação direta no dataframe.\n",
    "        * **Se você encontrar um problema complexo, uma metodologia que não conhece, ou se precisar de informações adicionais para interpretar um resultado (e.g., o que é um determinado conceito estatístico de série temporal, melhores práticas para lidar com certo tipo de anomalia, ou sobre um domínio específico que o dado representa), USE a ferramenta `tavily` para pesquisar antes de tomar uma decisão ou responder.**\n",
    "        * **Não invente respostas.** Se uma pergunta não pode ser respondida com as ferramentas disponíveis ou com pesquisa, declare isso claramente.\n",
    "    4.  **Clareza e Precisão**: Suas respostas devem ser claras, concisas e baseadas em evidências do dataset ou da pesquisa. Explique os insights de forma acessível.\n",
    "    5.  **Iteração**: Se uma pergunta inicial não for totalmente respondida ou se você identificar um caminho de análise promissor, sugira os próximos passos.\n",
    "\n",
    "    Sua meta é ser um assistente proativo e investigativo, garantindo que a EDA seja completa e perspicaz, especialmente para dados de séries temporais.\n",
    "    O dataset representa uma série temporal.\n",
    "\n",
    "    **Instrução Crítica para Imputação:**\n",
    "        Para usar qualquer ferramenta de imputação de dados, você deve seguir este procedimento rigoroso:\n",
    "        1.  **Isolar os dados:** Remova temporariamente todas as colunas não numéricas (como timestamp ou IDs) e colunas auxiliares do df.\n",
    "        2.  **Realizar a imputação:** Aplique a ferramenta de imputação APENAS na porção do dataframe que contém os dados numéricos da série temporal.\n",
    "        3.  **Restaurar o dataframe:** Após a imputação, reintegre as colunas que foram removidas temporariamente.\n",
    "\n",
    "    O dataset já está em formato pandas e se chama df.\n",
    "    \"\"\" \n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68cf04ac",
   "metadata": {},
   "source": [
    "### Definições LangChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "986c622b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x2ccbb05be10>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class State(TypedDict):\n",
    "    messages: list\n",
    "    logs: list\n",
    "    all_tool_outputs: list\n",
    "\n",
    "graph_builder = StateGraph(State)\n",
    "\n",
    "def chatbot(state: State):\n",
    "    return {\"messages\": [agent.invoke(state[\"messages\"])]}\n",
    "\n",
    "# Nó de ferramentas\n",
    "def tool_node(state: State):\n",
    "    print(\"Nó de ferramentas chamado com estado:\", state)\n",
    "    return ToolNode(tools=tools)(state)\n",
    "\n",
    "# Adicionando os nós simplificados\n",
    "graph_builder.add_node(\"chatbot\", chatbot)\n",
    "graph_builder.add_node(\"tools\", tool_node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d7dd5dea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "graph_builder.add_edge(START, \"chatbot\")\n",
    "\n",
    "# As arestas condicionais e de volta para o chatbot\n",
    "graph_builder.add_conditional_edges(\"chatbot\", tools_condition)\n",
    "graph_builder.add_edge(\"tools\", \"chatbot\")\n",
    "\n",
    "\n",
    "checkpointer = MemorySaver()\n",
    "config = {\n",
    "    \"configurable\": {\n",
    "        \"model\": llm,\n",
    "        \"thread_id\": \"1\"\n",
    "    }\n",
    "}\n",
    "graph = graph_builder.compile(checkpointer=checkpointer)\n",
    "from IPython.display import Image, display\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6181c141",
   "metadata": {},
   "source": [
    "### Agent Prompting\n",
    "Essa é a parte que estava focando. Estava tentando usar \"Iterative Refinement Prompting\" & \"Reasoning and Acting\"\n",
    "Entretanto o próprio agent_dataframe ja faz essas coisas, então apenas usei o prefixo com a estratégia de persona, e o sufixo com informações do dataset.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f325ddc5",
   "metadata": {},
   "source": [
    "### Tentando conversar com o agente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e53543a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: Para verificar a existência de nulos no dataset e lidar com eles, primeiro preciso entender a estrutura dos dados e identificar se há valores ausentes. Vou começar verificando a presença de valores nulos no dataframe `df`.\n",
      "\n",
      "Action: python_repl_ast\n",
      "Action Input: df.isnull().sum()\u001b[0m\u001b[36;1m\u001b[1;3mtimestamp       0\n",
      "313344       1274\n",
      "313349       1320\n",
      "313438       1245\n",
      "313450       1377\n",
      "             ... \n",
      "313184       1343\n",
      "313190       1290\n",
      "313197       1353\n",
      "313204       1338\n",
      "313339       1282\n",
      "Length: 359, dtype: int64\u001b[0m\u001b[32;1m\u001b[1;3mO dataframe `df` contém valores nulos em várias colunas, exceto na coluna 'timestamp'. A quantidade de valores nulos varia entre as colunas. Para lidar com esses valores nulos, preciso escolher um método de imputação adequado para séries temporais.\n",
      "\n",
      "Considerando que o dataset representa uma série temporal e que as colunas numéricas têm missing data, vou usar uma ferramenta de imputação adequada para séries temporais. A ferramenta `imputacao_stmw` parece apropriada, pois é indicada para séries temporais multivariadas e dados onde valores recentes são mais relevantes.\n",
      "\n",
      "Antes de aplicar a imputação, preciso isolar as colunas numéricas do dataframe, pois as ferramentas de imputação trabalham apenas com dados numéricos.\n",
      "\n",
      "Action: python_repl_ast\n",
      "Action Input: df_num = df.select_dtypes(include=['int64', 'float64']); df_num.head()\u001b[0m\u001b[36;1m\u001b[1;3m   313344  313349  313438  313450  313487  313493  313512  313551  313552  \\\n",
      "0    20.0    20.0   182.0   182.0    91.0   182.0   136.0    91.0    91.0   \n",
      "1    22.0    22.0   174.0   174.0    87.0     NaN     NaN    87.0    87.0   \n",
      "2    22.0    22.0   183.0   183.0    92.0   183.0   139.0    92.0    92.0   \n",
      "3    50.0    49.0   137.0   139.0     NaN     NaN   111.0    57.0    55.0   \n",
      "4    37.0    35.0   128.0   123.0     NaN   131.0   111.0    46.0    52.0   \n",
      "\n",
      "   317752  313658  317814  317815  317842  317843  317852  317853  315804  \\\n",
      "0   136.0   228.0   136.0   136.0    91.0   136.0   182.0   182.0   136.0   \n",
      "1   131.0   218.0   131.0   131.0     NaN   131.0   174.0   174.0   131.0   \n",
      "2   139.0   229.0   139.0   139.0    92.0   139.0   183.0   183.0   139.0   \n",
      "3    99.0    99.0   105.0   109.0     NaN   123.0    96.0    76.0    67.0   \n",
      "4     NaN    85.0    91.0    98.0    86.0   143.0   103.0    97.0    31.0   \n",
      "\n",
      "   317861  317862  313772  317869  315822  317870  315823  315824  315826  \\\n",
      "0    91.0    91.0   228.0    91.0    46.0     NaN    46.0    46.0    46.0   \n",
      "1    87.0    87.0   218.0    87.0    44.0    87.0    44.0    44.0    44.0   \n",
      "2    92.0    92.0   229.0    92.0    46.0    92.0    46.0    46.0    46.0   \n",
      "3    88.0    88.0    84.0    88.0     8.0    65.0    13.0    42.0    44.0   \n",
      "4    80.0    80.0    67.0    80.0    16.0    59.0     8.0    24.0    40.0   \n",
      "\n",
      "   315827  315828  315825  315830  315831  315833  315834  315835  317884  \\\n",
      "0    46.0    46.0    46.0    46.0    46.0    46.0    46.0    46.0   136.0   \n",
      "1    44.0    44.0    44.0     NaN    44.0    44.0    44.0    44.0   131.0   \n",
      "2    46.0    46.0    46.0    46.0    46.0    46.0    46.0    46.0   139.0   \n",
      "3    19.0     7.0    17.0    44.0    44.0    17.0    44.0    24.0    89.0   \n",
      "4    15.0     5.0     9.0    40.0    40.0     7.0    40.0    30.0    58.0   \n",
      "\n",
      "   317885  315836  315837  315838  315841  315842  315839  315843  315846  \\\n",
      "0   136.0    46.0    46.0    46.0    46.0    46.0    46.0    46.0    46.0   \n",
      "1   131.0    44.0     NaN    44.0    44.0    44.0    44.0     NaN    44.0   \n",
      "2   139.0    46.0    46.0    46.0    46.0    46.0    46.0    46.0    46.0   \n",
      "3   113.0    13.0    17.0     7.0    16.0    12.0    17.0    10.0    24.0   \n",
      "4    96.0    14.0     NaN    20.0     NaN    12.0    22.0    18.0    23.0   \n",
      "\n",
      "   315847  317895  315849  315850  317896  315852  315853  317902  317903  \\\n",
      "0    46.0    46.0    46.0    46.0   182.0    46.0    46.0    46.0   136.0   \n",
      "1    44.0    44.0    44.0    44.0     NaN    44.0    44.0    44.0     NaN   \n",
      "2    46.0    46.0    46.0    46.0   183.0    46.0    46.0     NaN   139.0   \n",
      "3    14.0    44.0    11.0    11.0   171.0    12.0    18.0    22.0   146.0   \n",
      "4    19.0    40.0    18.0     NaN   161.0    23.0    20.0    23.0   158.0   \n",
      "\n",
      "   315854  315855  315856  315858  315860  315861  317909  317910  315857  \\\n",
      "0    46.0     NaN    46.0    46.0    46.0    46.0    46.0   136.0    46.0   \n",
      "1    44.0    44.0    44.0    44.0    44.0    44.0    44.0   131.0    44.0   \n",
      "2    46.0    46.0    46.0    46.0    46.0    46.0    46.0   139.0     NaN   \n",
      "3    22.0    32.0    44.0    44.0     6.0    13.0    69.0   148.0    44.0   \n",
      "4    22.0    33.0    37.0    40.0     7.0    16.0    69.0   153.0    40.0   \n",
      "\n",
      "   315866  315867  315872  315873  315874  315875  315879  315880  315882  \\\n",
      "0    46.0    46.0    46.0    46.0    46.0    46.0    46.0    46.0    46.0   \n",
      "1    44.0    44.0    44.0    44.0    44.0     NaN    44.0    44.0    44.0   \n",
      "2    46.0     NaN    46.0    46.0    46.0    46.0    46.0    46.0    46.0   \n",
      "3     5.0    10.0    19.0    22.0    17.0    10.0    21.0     8.0     NaN   \n",
      "4    13.0    14.0    20.0    19.0    18.0    13.0     NaN    17.0    10.0   \n",
      "\n",
      "   315883  317933  315886  315887  317934  315891  315892  315894  315895  \\\n",
      "0    46.0    46.0    46.0    46.0   136.0    46.0    46.0    46.0    46.0   \n",
      "1    44.0    44.0    44.0    44.0   131.0    44.0    44.0    44.0    44.0   \n",
      "2    46.0    46.0    46.0    46.0   139.0     NaN    46.0    46.0     NaN   \n",
      "3     2.0    14.0     5.0     0.0    80.0    50.0    13.0     4.0     6.0   \n",
      "4    10.0    13.0    16.0    16.0    84.0    27.0    16.0     5.0     7.0   \n",
      "\n",
      "   313846  317947  313852  315900  317948  315901  315904  315903  315907  \\\n",
      "0   182.0     NaN   182.0    46.0   136.0    46.0    46.0    46.0    46.0   \n",
      "1   174.0    44.0   174.0    44.0   131.0    44.0    44.0    44.0    44.0   \n",
      "2   183.0    46.0   183.0    46.0   139.0    46.0    46.0    46.0    46.0   \n",
      "3   128.0    44.0   176.0    21.0   132.0    21.0    17.0    17.0    12.0   \n",
      "4   107.0    40.0   160.0     9.0   120.0     8.0    14.0    13.0    12.0   \n",
      "\n",
      "   317956  315908  315910  315911  317960  315913  315914  315915  317974  \\\n",
      "0    46.0    46.0    46.0    46.0     NaN    46.0    46.0     NaN   136.0   \n",
      "1    44.0    44.0    44.0     NaN    87.0    44.0    44.0     NaN   131.0   \n",
      "2    46.0    46.0    46.0    46.0    92.0    46.0    46.0    46.0   139.0   \n",
      "3    44.0    14.0    16.0    19.0   159.0    12.0     6.0    10.0   141.0   \n",
      "4    40.0    12.0     7.0     6.0   169.0    10.0     7.0    12.0     NaN   \n",
      "\n",
      "   315927  315938  317998  315955  315969  318022  318028  318029  315982  \\\n",
      "0   182.0     NaN    46.0   136.0   182.0   136.0    46.0   136.0   136.0   \n",
      "1   174.0   174.0    44.0   131.0   174.0   131.0    44.0   131.0   131.0   \n",
      "2   183.0   183.0    46.0   139.0   183.0   139.0    46.0   139.0   139.0   \n",
      "3   116.0   142.0    46.0   143.0   124.0    32.0    27.0   163.0    87.0   \n",
      "4   150.0   142.0    54.0   144.0   147.0    37.0    28.0   152.0    66.0   \n",
      "\n",
      "   318035  318036  315993  311903  313951  316001  313956  318053  318052  \\\n",
      "0    46.0   136.0   136.0    63.0   136.0   136.0   136.0   136.0   136.0   \n",
      "1    44.0   131.0   131.0    62.0   131.0   131.0   131.0   131.0   131.0   \n",
      "2    46.0   139.0   139.0    57.0   139.0   139.0   139.0   139.0   139.0   \n",
      "3    27.0   176.0    90.0   102.0   182.0     NaN    47.0   136.0    99.0   \n",
      "4    25.0   167.0    95.0    83.0     NaN    71.0    61.0   152.0   105.0   \n",
      "\n",
      "   316009  316018  316019  311930  313979  318076  318077  316032  316045  \\\n",
      "0   136.0   136.0   136.0     0.0   136.0     NaN   136.0   136.0   136.0   \n",
      "1   131.0   131.0   131.0     0.0   131.0   131.0   131.0   131.0   131.0   \n",
      "2   139.0   139.0   139.0     0.0   139.0   139.0   139.0   139.0   139.0   \n",
      "3   103.0   107.0     NaN    15.0    67.0   153.0    68.0    74.0    90.0   \n",
      "4   100.0   101.0    74.0    21.0    62.0   150.0    74.0     NaN    90.0   \n",
      "\n",
      "   318102  314013  316063  316064  318113  316073  316074  314025  318126  \\\n",
      "0   136.0   136.0   182.0    46.0   136.0     0.0     0.0   136.0   182.0   \n",
      "1   131.0   131.0   174.0    44.0   131.0     0.0     0.0   131.0   174.0   \n",
      "2   139.0   139.0   183.0    46.0   139.0     0.0     0.0   139.0   183.0   \n",
      "3    61.0   154.0   106.0    27.0   131.0    52.0     4.0   154.0    72.0   \n",
      "4    55.0   126.0    93.0    24.0   121.0    56.0     7.0   126.0    56.0   \n",
      "\n",
      "   316084  316085  314036  318135  314042  318142  312010  316114  316118  \\\n",
      "0   136.0   136.0   136.0   182.0   136.0   182.0   113.0   182.0   136.0   \n",
      "1   131.0   131.0   131.0   174.0   131.0   174.0   109.0   174.0   131.0   \n",
      "2     NaN   139.0   139.0   183.0   139.0   183.0   115.0   183.0   139.0   \n",
      "3   104.0   108.0   121.0    85.0   121.0   106.0   137.0    97.0   132.0   \n",
      "4   114.0    96.0   110.0    80.0   110.0    90.0   138.0   110.0   154.0   \n",
      "\n",
      "   316129  318179  318180  314121  318218  316174  318236  312098  314147  \\\n",
      "0   136.0   136.0    91.0   136.0   228.0   136.0   136.0   115.0    91.0   \n",
      "1   131.0   131.0    87.0   131.0     NaN   131.0   131.0   109.0    87.0   \n",
      "2   139.0   139.0    92.0   139.0   229.0   139.0   139.0   115.0    92.0   \n",
      "3   118.0     NaN    88.0   108.0   190.0    85.0    94.0    55.0   106.0   \n",
      "4   126.0   148.0    80.0   119.0   208.0    70.0     NaN    43.0   115.0   \n",
      "\n",
      "   312103  314157  314165  312132  312133  312134  318282  312139  314217  \\\n",
      "0   119.0   182.0    91.0    20.0    20.0    20.0   182.0   123.0   136.0   \n",
      "1   115.0   174.0    87.0    22.0    22.0    22.0   174.0   127.0   131.0   \n",
      "2   121.0   183.0    92.0    22.0    22.0    22.0   183.0   117.0   139.0   \n",
      "3   126.0   214.0    54.0    66.0    62.0    53.0   112.0   205.0    45.0   \n",
      "4     NaN   267.0     NaN    56.0    49.0    50.0     NaN     NaN    55.0   \n",
      "\n",
      "   316271  314230  316279  316280  316281  312188  314241  314248  318354  \\\n",
      "0   182.0    91.0   182.0    46.0    46.0   119.0    91.0   136.0   228.0   \n",
      "1   174.0    87.0   174.0    44.0    44.0   115.0    87.0     NaN     NaN   \n",
      "2   183.0    92.0   183.0    46.0    46.0   121.0    92.0   139.0   229.0   \n",
      "3   132.0    40.0   144.0    44.0    44.0   116.0    39.0    62.0    61.0   \n",
      "4   116.0    36.0   144.0    40.0    40.0   114.0    35.0    56.0    57.0   \n",
      "\n",
      "   316314  312220  318366  316328  312233  312236  318383  318401  312264  \\\n",
      "0   228.0   115.0   182.0   228.0   136.0     NaN   182.0    91.0   115.0   \n",
      "1   218.0   109.0   174.0   218.0   131.0   115.0   174.0    87.0   109.0   \n",
      "2   229.0   115.0   183.0   229.0   139.0   121.0   183.0    92.0   115.0   \n",
      "3   188.0    69.0    61.0   203.0    60.0     NaN   103.0    52.0    67.0   \n",
      "4   168.0    86.0    56.0   192.0    65.0   145.0   101.0    32.0    75.0   \n",
      "\n",
      "   318412  316364  318421  318432  316387  316388  318443  316399  316400  \\\n",
      "0    91.0     0.0    91.0    91.0   228.0    46.0   182.0    91.0    46.0   \n",
      "1     NaN     0.0    87.0    87.0   218.0    44.0   174.0    87.0    44.0   \n",
      "2    92.0     0.0     NaN    92.0   229.0    46.0   183.0    92.0    46.0   \n",
      "3    28.0    66.0    49.0    18.0   190.0    23.0   115.0   108.0     NaN   \n",
      "4    27.0    78.0    36.0    21.0   153.0    24.0   111.0   129.0    24.0   \n",
      "\n",
      "   318451  316414  314371  312326  314379  316429  318484  316438  312343  \\\n",
      "0   228.0   182.0   182.0    63.0    91.0     0.0   136.0   165.0    63.0   \n",
      "1   218.0   174.0   174.0    63.0     NaN     0.0   131.0   174.0    62.0   \n",
      "2   229.0   183.0   183.0    57.0    92.0     0.0   139.0     NaN    57.0   \n",
      "3   106.0   115.0   102.0    85.0    56.0    26.0   125.0   183.0   104.0   \n",
      "4   111.0   107.0   119.0    73.0    49.0    30.0   132.0   174.0   115.0   \n",
      "\n",
      "   312346  318493  316451  314419  312382  318528  314433  312386  312388  \\\n",
      "0    63.0   228.0    78.0   182.0     NaN   182.0   182.0    63.0   114.0   \n",
      "1    62.0   218.0    83.0   174.0   144.0   174.0   174.0    62.0   109.0   \n",
      "2    57.0   229.0    80.0   183.0   132.0   183.0   183.0    57.0   116.0   \n",
      "3    77.0   155.0   121.0    24.0     NaN    76.0   115.0    70.0    85.0   \n",
      "4    69.0   151.0   106.0   154.0    57.0     NaN   153.0    74.0    84.0   \n",
      "\n",
      "   318540  314446  318550  318551  314460  312420  312421  312422  318565  \\\n",
      "0   182.0   182.0    46.0    91.0   182.0   114.0   158.0    63.0    46.0   \n",
      "1     NaN   174.0    44.0    87.0   174.0   109.0   158.0    62.0    44.0   \n",
      "2   183.0   183.0    46.0    92.0   183.0   116.0   160.0    57.0    46.0   \n",
      "3   149.0    65.0    12.0    68.0   100.0   160.0    98.0    81.0    44.0   \n",
      "4   201.0   147.0     9.0    45.0   136.0   165.0   100.0    82.0    40.0   \n",
      "\n",
      "   318566  312425  318575  318576  314485  312439  318586  314491  318593  \\\n",
      "0   182.0   114.0   136.0    46.0   182.0   104.0   182.0   228.0   136.0   \n",
      "1   174.0     NaN   131.0    44.0   174.0   109.0   174.0   218.0   131.0   \n",
      "2   183.0   116.0   139.0    46.0   183.0   105.0   183.0   229.0   139.0   \n",
      "3   116.0   113.0   121.0    44.0   126.0   110.0   115.0   148.0    96.0   \n",
      "4   100.0   118.0   125.0    40.0   170.0   131.0   143.0   189.0   113.0   \n",
      "\n",
      "   314501  318599  318611  318612  318620  318626  318632  318636  314548  \\\n",
      "0   136.0   182.0     NaN   136.0   182.0   182.0   182.0     NaN   228.0   \n",
      "1   131.0   174.0    44.0   131.0   174.0   174.0   174.0    37.0   218.0   \n",
      "2   139.0   183.0    46.0   139.0   183.0   183.0   183.0    50.0   229.0   \n",
      "3   101.0    84.0    10.0     NaN   126.0   133.0   211.0    25.0   142.0   \n",
      "4   125.0    83.0    17.0   137.0   130.0   116.0   118.0     NaN   154.0   \n",
      "\n",
      "   318649  318650  314559  318656  312513  312514  312517  312520  318665  \\\n",
      "0    18.0   168.0   182.0    46.0   158.0   124.0   158.0     NaN     NaN   \n",
      "1    20.0   163.0   174.0    44.0   158.0   128.0     NaN   128.0    44.0   \n",
      "2    22.0   163.0   183.0    46.0   160.0   116.0   160.0     NaN    46.0   \n",
      "3    16.0   116.0   118.0     7.0   113.0   117.0   163.0   106.0    21.0   \n",
      "4    17.0   113.0   138.0     5.0   118.0   125.0   159.0   103.0    18.0   \n",
      "\n",
      "   318666  312523  312525  312527  318674  312530  318680  314598  312562  \\\n",
      "0   178.0   124.0   124.0    63.0   228.0   157.0   182.0   136.0     NaN   \n",
      "1   167.0   128.0   128.0    62.0   218.0   158.0   174.0   131.0   128.0   \n",
      "2   176.0   116.0   116.0    57.0   229.0   160.0   183.0   139.0   115.0   \n",
      "3   145.0     NaN   105.0   102.0   160.0   215.0   121.0    91.0   238.0   \n",
      "4   139.0   100.0   103.0    94.0   155.0   189.0   125.0   100.0   200.0   \n",
      "\n",
      "   312564  312566  318711  314617  312570  318721  314625  318736  318742  \\\n",
      "0   157.0   125.0   136.0   136.0    91.0   182.0    91.0     0.0    46.0   \n",
      "1   158.0   144.0   131.0   131.0    87.0   174.0    87.0     0.0    44.0   \n",
      "2   160.0   132.0   139.0   139.0    92.0   183.0    92.0     0.0    46.0   \n",
      "3   224.0   175.0   144.0   102.0    95.0   102.0    82.0     NaN    44.0   \n",
      "4   227.0   165.0   121.0   131.0    95.0   105.0    63.0    84.0    40.0   \n",
      "\n",
      "   318744  314652  318753  318764  314668  318772  318773  318775  314681  \\\n",
      "0    46.0   136.0     0.0   195.0   182.0    46.0   228.0     NaN    91.0   \n",
      "1    44.0   131.0     0.0   188.0   174.0    44.0   218.0    44.0    87.0   \n",
      "2    46.0   139.0     0.0     NaN   183.0    46.0   229.0    46.0    92.0   \n",
      "3     9.0    98.0     3.0   178.0   106.0    44.0   128.0    19.0    78.0   \n",
      "4     7.0    82.0    11.0   121.0     NaN    40.0   123.0    10.0    93.0   \n",
      "\n",
      "   314689  318787  318788  312648  314697  314698  312651  318800  318801  \\\n",
      "0    91.0    46.0   182.0    63.0    91.0    91.0    63.0    46.0   181.0   \n",
      "1    87.0    44.0   174.0    62.0    87.0    87.0    62.0    44.0   172.0   \n",
      "2    92.0    46.0   183.0    57.0    92.0    92.0    57.0    46.0   195.0   \n",
      "3    47.0     4.0   131.0    61.0    88.0    40.0    60.0    44.0   153.0   \n",
      "4    46.0     6.0   109.0    48.0    84.0    41.0    47.0    40.0   132.0   \n",
      "\n",
      "   314711  314712  318815  318816  314730  318832  312689  312694  318844  \\\n",
      "0     0.0   182.0    46.0   182.0    91.0    34.0   157.0   157.0   154.0   \n",
      "1     0.0   174.0    44.0   174.0    87.0    22.0   158.0   158.0   155.0   \n",
      "2     0.0   183.0    46.0   183.0    92.0    27.0   160.0   160.0   160.0   \n",
      "3     0.0   126.0     2.0   147.0    71.0    23.0   103.0   113.0   133.0   \n",
      "4     0.0   117.0     3.0   123.0    71.0    13.0   125.0   126.0   100.0   \n",
      "\n",
      "   312745  312757  312771  312782  312804  312807  314876  314877  314886  \\\n",
      "0   158.0     NaN   158.0   115.0   104.0   115.0   136.0   136.0   136.0   \n",
      "1   158.0   158.0   158.0   109.0   109.0   109.0   131.0   131.0   131.0   \n",
      "2   160.0   160.0   160.0   115.0   105.0   115.0   139.0   139.0   139.0   \n",
      "3   141.0   153.0    90.0   242.0   193.0   155.0   124.0    86.0   131.0   \n",
      "4   157.0   193.0   131.0   215.0   189.0   160.0    82.0    78.0    86.0   \n",
      "\n",
      "   314899  312852  312854  312856  312857  312858  314909  312865  314923  \\\n",
      "0   136.0   136.0   136.0   136.0     NaN   119.0   182.0   104.0   182.0   \n",
      "1   131.0   131.0   131.0   131.0   158.0   114.0   174.0   109.0   174.0   \n",
      "2   139.0   139.0   139.0   139.0     NaN   121.0   183.0   105.0   183.0   \n",
      "3   124.0    88.0   101.0   132.0   188.0    72.0   118.0   139.0   149.0   \n",
      "4    82.0     NaN   101.0   120.0   215.0    84.0    94.0   156.0   133.0   \n",
      "\n",
      "   314936  312895  312896  312898  312900  314955  314968  314982  312940  \\\n",
      "0   182.0    63.0   114.0   114.0    63.0   182.0     NaN   182.0   114.0   \n",
      "1   174.0    63.0     NaN   109.0    62.0   174.0   174.0   174.0   109.0   \n",
      "2   183.0    57.0   116.0   116.0    57.0   183.0   183.0   183.0   116.0   \n",
      "3   134.0   153.0   129.0    99.0    83.0    91.0   133.0   179.0   112.0   \n",
      "4   114.0   164.0   142.0   113.0   103.0    60.0   121.0   110.0   131.0   \n",
      "\n",
      "   312942  312944  314994  312946  315006  317064  315017  315030  317081  \\\n",
      "0   114.0   114.0   228.0   125.0   228.0    46.0   182.0   182.0    91.0   \n",
      "1   109.0   109.0   218.0   144.0   218.0    44.0   174.0   174.0    87.0   \n",
      "2   116.0   116.0   229.0   132.0     NaN    46.0   183.0   183.0    92.0   \n",
      "3   107.0   106.0   127.0     NaN   139.0    19.0    77.0   144.0    81.0   \n",
      "4   131.0   141.0   153.0   117.0   156.0    22.0    60.0   151.0    90.0   \n",
      "\n",
      "   317088  315042  313000  313003  313005  315054  313010  315060  313035  \\\n",
      "0    91.0   182.0   115.0   124.0   124.0   182.0   124.0   136.0   113.0   \n",
      "1    87.0   174.0   109.0   128.0   128.0   174.0     NaN   131.0   109.0   \n",
      "2    92.0   183.0   115.0   115.0   115.0   183.0     0.0   139.0   115.0   \n",
      "3    14.0   132.0     NaN   100.0    78.0     NaN    82.0    70.0    78.0   \n",
      "4    14.0   147.0    70.0    69.0    70.0   166.0    72.0    61.0    77.0   \n",
      "\n",
      "   313037  317139  317141  317143  317146  313055  317157  317166  317168  \\\n",
      "0   182.0    91.0   136.0   136.0    91.0     NaN   136.0   136.0    46.0   \n",
      "1   174.0    87.0   131.0   131.0    87.0    23.0   131.0   131.0    44.0   \n",
      "2   183.0    92.0   139.0   139.0    92.0    23.0   139.0   139.0    46.0   \n",
      "3    71.0    49.0   122.0    48.0    84.0    72.0    44.0    46.0    22.0   \n",
      "4    71.0    55.0   114.0    49.0    81.0    59.0    44.0    39.0    14.0   \n",
      "\n",
      "   317171  313080  313082  313111  313114  313132  313144  313159  313166  \\\n",
      "0    46.0    63.0    20.0   102.0   104.0   102.0   158.0    63.0    63.0   \n",
      "1    44.0    62.0    22.0   109.0   109.0   109.0   158.0    62.0    62.0   \n",
      "2    46.0    57.0    22.0     NaN   105.0   105.0   160.0    57.0    57.0   \n",
      "3    24.0    58.0    78.0    97.0     NaN   107.0   174.0   109.0    30.0   \n",
      "4    17.0    57.0    84.0   125.0   129.0   106.0   162.0     NaN    31.0   \n",
      "\n",
      "   313172  313178  313184  313190  313197  313204  313339  \n",
      "0     NaN   125.0   114.0    63.0    63.0   115.0    63.0  \n",
      "1    62.0   144.0   109.0    62.0    63.0   109.0    62.0  \n",
      "2    57.0   131.0   116.0    57.0    57.0   115.0    57.0  \n",
      "3    58.0   106.0   102.0    52.0   111.0    88.0    48.0  \n",
      "4    55.0   109.0   127.0    49.0   109.0    76.0    47.0  \u001b[0m\u001b[32;1m\u001b[1;3mAgora que tenho as colunas numéricas isoladas em `df_num`, posso aplicar a imputação usando a ferramenta `imputacao_stmw`, que é adequada para séries temporais multivariadas.\n",
      "\n",
      "Action: imputacao_stmw\n",
      "Action Input: df_num\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Gabriel\\AppData\\Local\\Temp\\ipykernel_16784\\2950093071.py:93: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_trend'] = df[col].rolling(window=5).mean()\n",
      "C:\\Users\\Gabriel\\AppData\\Local\\Temp\\ipykernel_16784\\2950093071.py:93: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_trend'] = df[col].rolling(window=5).mean()\n",
      "C:\\Users\\Gabriel\\AppData\\Local\\Temp\\ipykernel_16784\\2950093071.py:93: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_trend'] = df[col].rolling(window=5).mean()\n",
      "C:\\Users\\Gabriel\\AppData\\Local\\Temp\\ipykernel_16784\\2950093071.py:93: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_trend'] = df[col].rolling(window=5).mean()\n",
      "C:\\Users\\Gabriel\\AppData\\Local\\Temp\\ipykernel_16784\\2950093071.py:93: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_trend'] = df[col].rolling(window=5).mean()\n",
      "C:\\Users\\Gabriel\\AppData\\Local\\Temp\\ipykernel_16784\\2950093071.py:93: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_trend'] = df[col].rolling(window=5).mean()\n",
      "C:\\Users\\Gabriel\\AppData\\Local\\Temp\\ipykernel_16784\\2950093071.py:93: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_trend'] = df[col].rolling(window=5).mean()\n",
      "C:\\Users\\Gabriel\\AppData\\Local\\Temp\\ipykernel_16784\\2950093071.py:93: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_trend'] = df[col].rolling(window=5).mean()\n",
      "C:\\Users\\Gabriel\\AppData\\Local\\Temp\\ipykernel_16784\\2950093071.py:93: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_trend'] = df[col].rolling(window=5).mean()\n",
      "C:\\Users\\Gabriel\\AppData\\Local\\Temp\\ipykernel_16784\\2950093071.py:93: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_trend'] = df[col].rolling(window=5).mean()\n",
      "C:\\Users\\Gabriel\\AppData\\Local\\Temp\\ipykernel_16784\\2950093071.py:93: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_trend'] = df[col].rolling(window=5).mean()\n",
      "C:\\Users\\Gabriel\\AppData\\Local\\Temp\\ipykernel_16784\\2950093071.py:93: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_trend'] = df[col].rolling(window=5).mean()\n",
      "C:\\Users\\Gabriel\\AppData\\Local\\Temp\\ipykernel_16784\\2950093071.py:93: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_trend'] = df[col].rolling(window=5).mean()\n",
      "C:\\Users\\Gabriel\\AppData\\Local\\Temp\\ipykernel_16784\\2950093071.py:93: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_trend'] = df[col].rolling(window=5).mean()\n",
      "C:\\Users\\Gabriel\\AppData\\Local\\Temp\\ipykernel_16784\\2950093071.py:93: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_trend'] = df[col].rolling(window=5).mean()\n",
      "C:\\Users\\Gabriel\\AppData\\Local\\Temp\\ipykernel_16784\\2950093071.py:93: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_trend'] = df[col].rolling(window=5).mean()\n",
      "C:\\Users\\Gabriel\\AppData\\Local\\Temp\\ipykernel_16784\\2950093071.py:93: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_trend'] = df[col].rolling(window=5).mean()\n",
      "C:\\Users\\Gabriel\\AppData\\Local\\Temp\\ipykernel_16784\\2950093071.py:93: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_trend'] = df[col].rolling(window=5).mean()\n",
      "C:\\Users\\Gabriel\\AppData\\Local\\Temp\\ipykernel_16784\\2950093071.py:93: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_trend'] = df[col].rolling(window=5).mean()\n",
      "C:\\Users\\Gabriel\\AppData\\Local\\Temp\\ipykernel_16784\\2950093071.py:93: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_trend'] = df[col].rolling(window=5).mean()\n",
      "C:\\Users\\Gabriel\\AppData\\Local\\Temp\\ipykernel_16784\\2950093071.py:93: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_trend'] = df[col].rolling(window=5).mean()\n",
      "C:\\Users\\Gabriel\\AppData\\Local\\Temp\\ipykernel_16784\\2950093071.py:93: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_trend'] = df[col].rolling(window=5).mean()\n",
      "C:\\Users\\Gabriel\\AppData\\Local\\Temp\\ipykernel_16784\\2950093071.py:93: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_trend'] = df[col].rolling(window=5).mean()\n",
      "C:\\Users\\Gabriel\\AppData\\Local\\Temp\\ipykernel_16784\\2950093071.py:93: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_trend'] = df[col].rolling(window=5).mean()\n",
      "C:\\Users\\Gabriel\\AppData\\Local\\Temp\\ipykernel_16784\\2950093071.py:93: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_trend'] = df[col].rolling(window=5).mean()\n",
      "C:\\Users\\Gabriel\\AppData\\Local\\Temp\\ipykernel_16784\\2950093071.py:93: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_trend'] = df[col].rolling(window=5).mean()\n",
      "C:\\Users\\Gabriel\\AppData\\Local\\Temp\\ipykernel_16784\\2950093071.py:93: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_trend'] = df[col].rolling(window=5).mean()\n",
      "C:\\Users\\Gabriel\\AppData\\Local\\Temp\\ipykernel_16784\\2950093071.py:93: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_trend'] = df[col].rolling(window=5).mean()\n",
      "C:\\Users\\Gabriel\\AppData\\Local\\Temp\\ipykernel_16784\\2950093071.py:93: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_trend'] = df[col].rolling(window=5).mean()\n",
      "C:\\Users\\Gabriel\\AppData\\Local\\Temp\\ipykernel_16784\\2950093071.py:93: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_trend'] = df[col].rolling(window=5).mean()\n",
      "C:\\Users\\Gabriel\\AppData\\Local\\Temp\\ipykernel_16784\\2950093071.py:93: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_trend'] = df[col].rolling(window=5).mean()\n",
      "C:\\Users\\Gabriel\\AppData\\Local\\Temp\\ipykernel_16784\\2950093071.py:93: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_trend'] = df[col].rolling(window=5).mean()\n",
      "C:\\Users\\Gabriel\\AppData\\Local\\Temp\\ipykernel_16784\\2950093071.py:93: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_trend'] = df[col].rolling(window=5).mean()\n",
      "C:\\Users\\Gabriel\\AppData\\Local\\Temp\\ipykernel_16784\\2950093071.py:93: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_trend'] = df[col].rolling(window=5).mean()\n",
      "C:\\Users\\Gabriel\\AppData\\Local\\Temp\\ipykernel_16784\\2950093071.py:93: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_trend'] = df[col].rolling(window=5).mean()\n",
      "C:\\Users\\Gabriel\\AppData\\Local\\Temp\\ipykernel_16784\\2950093071.py:93: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_trend'] = df[col].rolling(window=5).mean()\n",
      "C:\\Users\\Gabriel\\AppData\\Local\\Temp\\ipykernel_16784\\2950093071.py:93: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_trend'] = df[col].rolling(window=5).mean()\n",
      "C:\\Users\\Gabriel\\AppData\\Local\\Temp\\ipykernel_16784\\2950093071.py:93: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_trend'] = df[col].rolling(window=5).mean()\n",
      "C:\\Users\\Gabriel\\AppData\\Local\\Temp\\ipykernel_16784\\2950093071.py:93: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_trend'] = df[col].rolling(window=5).mean()\n",
      "C:\\Users\\Gabriel\\AppData\\Local\\Temp\\ipykernel_16784\\2950093071.py:93: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_trend'] = df[col].rolling(window=5).mean()\n",
      "C:\\Users\\Gabriel\\AppData\\Local\\Temp\\ipykernel_16784\\2950093071.py:93: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_trend'] = df[col].rolling(window=5).mean()\n",
      "C:\\Users\\Gabriel\\AppData\\Local\\Temp\\ipykernel_16784\\2950093071.py:93: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_trend'] = df[col].rolling(window=5).mean()\n",
      "C:\\Users\\Gabriel\\AppData\\Local\\Temp\\ipykernel_16784\\2950093071.py:93: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_trend'] = df[col].rolling(window=5).mean()\n",
      "C:\\Users\\Gabriel\\AppData\\Local\\Temp\\ipykernel_16784\\2950093071.py:93: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_trend'] = df[col].rolling(window=5).mean()\n",
      "C:\\Users\\Gabriel\\AppData\\Local\\Temp\\ipykernel_16784\\2950093071.py:93: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_trend'] = df[col].rolling(window=5).mean()\n",
      "C:\\Users\\Gabriel\\AppData\\Local\\Temp\\ipykernel_16784\\2950093071.py:93: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_trend'] = df[col].rolling(window=5).mean()\n",
      "C:\\Users\\Gabriel\\AppData\\Local\\Temp\\ipykernel_16784\\2950093071.py:93: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_trend'] = df[col].rolling(window=5).mean()\n",
      "C:\\Users\\Gabriel\\AppData\\Local\\Temp\\ipykernel_16784\\2950093071.py:93: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_trend'] = df[col].rolling(window=5).mean()\n",
      "C:\\Users\\Gabriel\\AppData\\Local\\Temp\\ipykernel_16784\\2950093071.py:93: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_trend'] = df[col].rolling(window=5).mean()\n",
      "C:\\Users\\Gabriel\\AppData\\Local\\Temp\\ipykernel_16784\\2950093071.py:93: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_trend'] = df[col].rolling(window=5).mean()\n",
      "C:\\Users\\Gabriel\\AppData\\Local\\Temp\\ipykernel_16784\\2950093071.py:93: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_trend'] = df[col].rolling(window=5).mean()\n",
      "C:\\Users\\Gabriel\\AppData\\Local\\Temp\\ipykernel_16784\\2950093071.py:93: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_trend'] = df[col].rolling(window=5).mean()\n",
      "C:\\Users\\Gabriel\\AppData\\Local\\Temp\\ipykernel_16784\\2950093071.py:93: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_trend'] = df[col].rolling(window=5).mean()\n",
      "C:\\Users\\Gabriel\\AppData\\Local\\Temp\\ipykernel_16784\\2950093071.py:93: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_trend'] = df[col].rolling(window=5).mean()\n",
      "C:\\Users\\Gabriel\\AppData\\Local\\Temp\\ipykernel_16784\\2950093071.py:93: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_trend'] = df[col].rolling(window=5).mean()\n",
      "C:\\Users\\Gabriel\\AppData\\Local\\Temp\\ipykernel_16784\\2950093071.py:93: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_trend'] = df[col].rolling(window=5).mean()\n",
      "C:\\Users\\Gabriel\\AppData\\Local\\Temp\\ipykernel_16784\\2950093071.py:93: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_trend'] = df[col].rolling(window=5).mean()\n",
      "C:\\Users\\Gabriel\\AppData\\Local\\Temp\\ipykernel_16784\\2950093071.py:93: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_trend'] = df[col].rolling(window=5).mean()\n",
      "C:\\Users\\Gabriel\\AppData\\Local\\Temp\\ipykernel_16784\\2950093071.py:93: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_trend'] = df[col].rolling(window=5).mean()\n",
      "C:\\Users\\Gabriel\\AppData\\Local\\Temp\\ipykernel_16784\\2950093071.py:93: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_trend'] = df[col].rolling(window=5).mean()\n",
      "C:\\Users\\Gabriel\\AppData\\Local\\Temp\\ipykernel_16784\\2950093071.py:93: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_trend'] = df[col].rolling(window=5).mean()\n",
      "C:\\Users\\Gabriel\\AppData\\Local\\Temp\\ipykernel_16784\\2950093071.py:93: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_trend'] = df[col].rolling(window=5).mean()\n",
      "C:\\Users\\Gabriel\\AppData\\Local\\Temp\\ipykernel_16784\\2950093071.py:93: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_trend'] = df[col].rolling(window=5).mean()\n",
      "C:\\Users\\Gabriel\\AppData\\Local\\Temp\\ipykernel_16784\\2950093071.py:93: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_trend'] = df[col].rolling(window=5).mean()\n",
      "C:\\Users\\Gabriel\\AppData\\Local\\Temp\\ipykernel_16784\\2950093071.py:93: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_trend'] = df[col].rolling(window=5).mean()\n",
      "C:\\Users\\Gabriel\\AppData\\Local\\Temp\\ipykernel_16784\\2950093071.py:93: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_trend'] = df[col].rolling(window=5).mean()\n",
      "C:\\Users\\Gabriel\\AppData\\Local\\Temp\\ipykernel_16784\\2950093071.py:93: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_trend'] = df[col].rolling(window=5).mean()\n",
      "C:\\Users\\Gabriel\\AppData\\Local\\Temp\\ipykernel_16784\\2950093071.py:93: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_trend'] = df[col].rolling(window=5).mean()\n",
      "C:\\Users\\Gabriel\\AppData\\Local\\Temp\\ipykernel_16784\\2950093071.py:93: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_trend'] = df[col].rolling(window=5).mean()\n",
      "C:\\Users\\Gabriel\\AppData\\Local\\Temp\\ipykernel_16784\\2950093071.py:93: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_trend'] = df[col].rolling(window=5).mean()\n",
      "C:\\Users\\Gabriel\\AppData\\Local\\Temp\\ipykernel_16784\\2950093071.py:93: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_trend'] = df[col].rolling(window=5).mean()\n",
      "C:\\Users\\Gabriel\\AppData\\Local\\Temp\\ipykernel_16784\\2950093071.py:93: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_trend'] = df[col].rolling(window=5).mean()\n",
      "C:\\Users\\Gabriel\\AppData\\Local\\Temp\\ipykernel_16784\\2950093071.py:93: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_trend'] = df[col].rolling(window=5).mean()\n",
      "C:\\Users\\Gabriel\\AppData\\Local\\Temp\\ipykernel_16784\\2950093071.py:93: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_trend'] = df[col].rolling(window=5).mean()\n",
      "C:\\Users\\Gabriel\\AppData\\Local\\Temp\\ipykernel_16784\\2950093071.py:93: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_trend'] = df[col].rolling(window=5).mean()\n",
      "C:\\Users\\Gabriel\\AppData\\Local\\Temp\\ipykernel_16784\\2950093071.py:93: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_trend'] = df[col].rolling(window=5).mean()\n",
      "C:\\Users\\Gabriel\\AppData\\Local\\Temp\\ipykernel_16784\\2950093071.py:93: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_trend'] = df[col].rolling(window=5).mean()\n",
      "C:\\Users\\Gabriel\\AppData\\Local\\Temp\\ipykernel_16784\\2950093071.py:93: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_trend'] = df[col].rolling(window=5).mean()\n",
      "C:\\Users\\Gabriel\\AppData\\Local\\Temp\\ipykernel_16784\\2950093071.py:93: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_trend'] = df[col].rolling(window=5).mean()\n",
      "C:\\Users\\Gabriel\\AppData\\Local\\Temp\\ipykernel_16784\\2950093071.py:93: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_trend'] = df[col].rolling(window=5).mean()\n",
      "C:\\Users\\Gabriel\\AppData\\Local\\Temp\\ipykernel_16784\\2950093071.py:93: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_trend'] = df[col].rolling(window=5).mean()\n",
      "C:\\Users\\Gabriel\\AppData\\Local\\Temp\\ipykernel_16784\\2950093071.py:93: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_trend'] = df[col].rolling(window=5).mean()\n",
      "C:\\Users\\Gabriel\\AppData\\Local\\Temp\\ipykernel_16784\\2950093071.py:93: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_trend'] = df[col].rolling(window=5).mean()\n",
      "C:\\Users\\Gabriel\\AppData\\Local\\Temp\\ipykernel_16784\\2950093071.py:93: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_trend'] = df[col].rolling(window=5).mean()\n",
      "C:\\Users\\Gabriel\\AppData\\Local\\Temp\\ipykernel_16784\\2950093071.py:93: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_trend'] = df[col].rolling(window=5).mean()\n",
      "C:\\Users\\Gabriel\\AppData\\Local\\Temp\\ipykernel_16784\\2950093071.py:93: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_trend'] = df[col].rolling(window=5).mean()\n",
      "C:\\Users\\Gabriel\\AppData\\Local\\Temp\\ipykernel_16784\\2950093071.py:93: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_trend'] = df[col].rolling(window=5).mean()\n",
      "C:\\Users\\Gabriel\\AppData\\Local\\Temp\\ipykernel_16784\\2950093071.py:93: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_trend'] = df[col].rolling(window=5).mean()\n",
      "C:\\Users\\Gabriel\\AppData\\Local\\Temp\\ipykernel_16784\\2950093071.py:93: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_trend'] = df[col].rolling(window=5).mean()\n",
      "C:\\Users\\Gabriel\\AppData\\Local\\Temp\\ipykernel_16784\\2950093071.py:93: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_trend'] = df[col].rolling(window=5).mean()\n",
      "C:\\Users\\Gabriel\\AppData\\Local\\Temp\\ipykernel_16784\\2950093071.py:93: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_trend'] = df[col].rolling(window=5).mean()\n",
      "C:\\Users\\Gabriel\\AppData\\Local\\Temp\\ipykernel_16784\\2950093071.py:93: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_trend'] = df[col].rolling(window=5).mean()\n",
      "C:\\Users\\Gabriel\\AppData\\Local\\Temp\\ipykernel_16784\\2950093071.py:93: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_trend'] = df[col].rolling(window=5).mean()\n",
      "C:\\Users\\Gabriel\\AppData\\Local\\Temp\\ipykernel_16784\\2950093071.py:93: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_trend'] = df[col].rolling(window=5).mean()\n",
      "C:\\Users\\Gabriel\\AppData\\Local\\Temp\\ipykernel_16784\\2950093071.py:93: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_trend'] = df[col].rolling(window=5).mean()\n",
      "C:\\Users\\Gabriel\\AppData\\Local\\Temp\\ipykernel_16784\\2950093071.py:93: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_trend'] = df[col].rolling(window=5).mean()\n",
      "C:\\Users\\Gabriel\\AppData\\Local\\Temp\\ipykernel_16784\\2950093071.py:93: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_trend'] = df[col].rolling(window=5).mean()\n",
      "C:\\Users\\Gabriel\\AppData\\Local\\Temp\\ipykernel_16784\\2950093071.py:93: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_trend'] = df[col].rolling(window=5).mean()\n",
      "C:\\Users\\Gabriel\\AppData\\Local\\Temp\\ipykernel_16784\\2950093071.py:93: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_trend'] = df[col].rolling(window=5).mean()\n",
      "C:\\Users\\Gabriel\\AppData\\Local\\Temp\\ipykernel_16784\\2950093071.py:93: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_trend'] = df[col].rolling(window=5).mean()\n",
      "C:\\Users\\Gabriel\\AppData\\Local\\Temp\\ipykernel_16784\\2950093071.py:93: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_trend'] = df[col].rolling(window=5).mean()\n",
      "C:\\Users\\Gabriel\\AppData\\Local\\Temp\\ipykernel_16784\\2950093071.py:93: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_trend'] = df[col].rolling(window=5).mean()\n",
      "C:\\Users\\Gabriel\\AppData\\Local\\Temp\\ipykernel_16784\\2950093071.py:93: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_trend'] = df[col].rolling(window=5).mean()\n",
      "C:\\Users\\Gabriel\\AppData\\Local\\Temp\\ipykernel_16784\\2950093071.py:93: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_trend'] = df[col].rolling(window=5).mean()\n",
      "C:\\Users\\Gabriel\\AppData\\Local\\Temp\\ipykernel_16784\\2950093071.py:93: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_trend'] = df[col].rolling(window=5).mean()\n",
      "C:\\Users\\Gabriel\\AppData\\Local\\Temp\\ipykernel_16784\\2950093071.py:93: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_trend'] = df[col].rolling(window=5).mean()\n",
      "C:\\Users\\Gabriel\\AppData\\Local\\Temp\\ipykernel_16784\\2950093071.py:93: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_trend'] = df[col].rolling(window=5).mean()\n",
      "C:\\Users\\Gabriel\\AppData\\Local\\Temp\\ipykernel_16784\\2950093071.py:93: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_trend'] = df[col].rolling(window=5).mean()\n",
      "C:\\Users\\Gabriel\\AppData\\Local\\Temp\\ipykernel_16784\\2950093071.py:93: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_trend'] = df[col].rolling(window=5).mean()\n",
      "C:\\Users\\Gabriel\\AppData\\Local\\Temp\\ipykernel_16784\\2950093071.py:93: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_trend'] = df[col].rolling(window=5).mean()\n",
      "C:\\Users\\Gabriel\\AppData\\Local\\Temp\\ipykernel_16784\\2950093071.py:93: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_trend'] = df[col].rolling(window=5).mean()\n",
      "C:\\Users\\Gabriel\\AppData\\Local\\Temp\\ipykernel_16784\\2950093071.py:93: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_trend'] = df[col].rolling(window=5).mean()\n",
      "C:\\Users\\Gabriel\\AppData\\Local\\Temp\\ipykernel_16784\\2950093071.py:93: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_trend'] = df[col].rolling(window=5).mean()\n",
      "C:\\Users\\Gabriel\\AppData\\Local\\Temp\\ipykernel_16784\\2950093071.py:93: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_trend'] = df[col].rolling(window=5).mean()\n",
      "C:\\Users\\Gabriel\\AppData\\Local\\Temp\\ipykernel_16784\\2950093071.py:93: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_trend'] = df[col].rolling(window=5).mean()\n",
      "C:\\Users\\Gabriel\\AppData\\Local\\Temp\\ipykernel_16784\\2950093071.py:93: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_trend'] = df[col].rolling(window=5).mean()\n",
      "C:\\Users\\Gabriel\\AppData\\Local\\Temp\\ipykernel_16784\\2950093071.py:93: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_trend'] = df[col].rolling(window=5).mean()\n",
      "C:\\Users\\Gabriel\\AppData\\Local\\Temp\\ipykernel_16784\\2950093071.py:93: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_trend'] = df[col].rolling(window=5).mean()\n",
      "C:\\Users\\Gabriel\\AppData\\Local\\Temp\\ipykernel_16784\\2950093071.py:93: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_trend'] = df[col].rolling(window=5).mean()\n",
      "C:\\Users\\Gabriel\\AppData\\Local\\Temp\\ipykernel_16784\\2950093071.py:93: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_trend'] = df[col].rolling(window=5).mean()\n",
      "C:\\Users\\Gabriel\\AppData\\Local\\Temp\\ipykernel_16784\\2950093071.py:93: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_trend'] = df[col].rolling(window=5).mean()\n",
      "C:\\Users\\Gabriel\\AppData\\Local\\Temp\\ipykernel_16784\\2950093071.py:93: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_trend'] = df[col].rolling(window=5).mean()\n",
      "C:\\Users\\Gabriel\\AppData\\Local\\Temp\\ipykernel_16784\\2950093071.py:93: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_trend'] = df[col].rolling(window=5).mean()\n",
      "C:\\Users\\Gabriel\\AppData\\Local\\Temp\\ipykernel_16784\\2950093071.py:93: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_trend'] = df[col].rolling(window=5).mean()\n",
      "C:\\Users\\Gabriel\\AppData\\Local\\Temp\\ipykernel_16784\\2950093071.py:93: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_trend'] = df[col].rolling(window=5).mean()\n",
      "C:\\Users\\Gabriel\\AppData\\Local\\Temp\\ipykernel_16784\\2950093071.py:93: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_trend'] = df[col].rolling(window=5).mean()\n",
      "C:\\Users\\Gabriel\\AppData\\Local\\Temp\\ipykernel_16784\\2950093071.py:93: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_trend'] = df[col].rolling(window=5).mean()\n",
      "C:\\Users\\Gabriel\\AppData\\Local\\Temp\\ipykernel_16784\\2950093071.py:93: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_trend'] = df[col].rolling(window=5).mean()\n",
      "C:\\Users\\Gabriel\\AppData\\Local\\Temp\\ipykernel_16784\\2950093071.py:93: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_trend'] = df[col].rolling(window=5).mean()\n",
      "C:\\Users\\Gabriel\\AppData\\Local\\Temp\\ipykernel_16784\\2950093071.py:93: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_trend'] = df[col].rolling(window=5).mean()\n",
      "C:\\Users\\Gabriel\\AppData\\Local\\Temp\\ipykernel_16784\\2950093071.py:93: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_trend'] = df[col].rolling(window=5).mean()\n",
      "C:\\Users\\Gabriel\\AppData\\Local\\Temp\\ipykernel_16784\\2950093071.py:93: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_trend'] = df[col].rolling(window=5).mean()\n",
      "C:\\Users\\Gabriel\\AppData\\Local\\Temp\\ipykernel_16784\\2950093071.py:93: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_trend'] = df[col].rolling(window=5).mean()\n",
      "C:\\Users\\Gabriel\\AppData\\Local\\Temp\\ipykernel_16784\\2950093071.py:93: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_trend'] = df[col].rolling(window=5).mean()\n",
      "C:\\Users\\Gabriel\\AppData\\Local\\Temp\\ipykernel_16784\\2950093071.py:93: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_trend'] = df[col].rolling(window=5).mean()\n",
      "C:\\Users\\Gabriel\\AppData\\Local\\Temp\\ipykernel_16784\\2950093071.py:93: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_trend'] = df[col].rolling(window=5).mean()\n",
      "C:\\Users\\Gabriel\\AppData\\Local\\Temp\\ipykernel_16784\\2950093071.py:93: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_trend'] = df[col].rolling(window=5).mean()\n",
      "C:\\Users\\Gabriel\\AppData\\Local\\Temp\\ipykernel_16784\\2950093071.py:93: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_trend'] = df[col].rolling(window=5).mean()\n",
      "C:\\Users\\Gabriel\\AppData\\Local\\Temp\\ipykernel_16784\\2950093071.py:93: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_trend'] = df[col].rolling(window=5).mean()\n",
      "C:\\Users\\Gabriel\\AppData\\Local\\Temp\\ipykernel_16784\\2950093071.py:93: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_trend'] = df[col].rolling(window=5).mean()\n",
      "C:\\Users\\Gabriel\\AppData\\Local\\Temp\\ipykernel_16784\\2950093071.py:93: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_trend'] = df[col].rolling(window=5).mean()\n",
      "C:\\Users\\Gabriel\\AppData\\Local\\Temp\\ipykernel_16784\\2950093071.py:93: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_trend'] = df[col].rolling(window=5).mean()\n",
      "C:\\Users\\Gabriel\\AppData\\Local\\Temp\\ipykernel_16784\\2950093071.py:93: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_trend'] = df[col].rolling(window=5).mean()\n",
      "C:\\Users\\Gabriel\\AppData\\Local\\Temp\\ipykernel_16784\\2950093071.py:93: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_trend'] = df[col].rolling(window=5).mean()\n",
      "C:\\Users\\Gabriel\\AppData\\Local\\Temp\\ipykernel_16784\\2950093071.py:93: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_trend'] = df[col].rolling(window=5).mean()\n",
      "C:\\Users\\Gabriel\\AppData\\Local\\Temp\\ipykernel_16784\\2950093071.py:93: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_trend'] = df[col].rolling(window=5).mean()\n",
      "C:\\Users\\Gabriel\\AppData\\Local\\Temp\\ipykernel_16784\\2950093071.py:93: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_trend'] = df[col].rolling(window=5).mean()\n",
      "C:\\Users\\Gabriel\\AppData\\Local\\Temp\\ipykernel_16784\\2950093071.py:93: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_trend'] = df[col].rolling(window=5).mean()\n",
      "C:\\Users\\Gabriel\\AppData\\Local\\Temp\\ipykernel_16784\\2950093071.py:93: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_trend'] = df[col].rolling(window=5).mean()\n",
      "C:\\Users\\Gabriel\\AppData\\Local\\Temp\\ipykernel_16784\\2950093071.py:93: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_trend'] = df[col].rolling(window=5).mean()\n",
      "C:\\Users\\Gabriel\\AppData\\Local\\Temp\\ipykernel_16784\\2950093071.py:93: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_trend'] = df[col].rolling(window=5).mean()\n",
      "C:\\Users\\Gabriel\\AppData\\Local\\Temp\\ipykernel_16784\\2950093071.py:93: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_trend'] = df[col].rolling(window=5).mean()\n",
      "C:\\Users\\Gabriel\\AppData\\Local\\Temp\\ipykernel_16784\\2950093071.py:93: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_trend'] = df[col].rolling(window=5).mean()\n",
      "C:\\Users\\Gabriel\\AppData\\Local\\Temp\\ipykernel_16784\\2950093071.py:93: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_trend'] = df[col].rolling(window=5).mean()\n",
      "C:\\Users\\Gabriel\\AppData\\Local\\Temp\\ipykernel_16784\\2950093071.py:93: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_trend'] = df[col].rolling(window=5).mean()\n",
      "C:\\Users\\Gabriel\\AppData\\Local\\Temp\\ipykernel_16784\\2950093071.py:93: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_trend'] = df[col].rolling(window=5).mean()\n",
      "C:\\Users\\Gabriel\\AppData\\Local\\Temp\\ipykernel_16784\\2950093071.py:93: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_trend'] = df[col].rolling(window=5).mean()\n",
      "C:\\Users\\Gabriel\\AppData\\Local\\Temp\\ipykernel_16784\\2950093071.py:93: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_trend'] = df[col].rolling(window=5).mean()\n",
      "C:\\Users\\Gabriel\\AppData\\Local\\Temp\\ipykernel_16784\\2950093071.py:93: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_trend'] = df[col].rolling(window=5).mean()\n",
      "C:\\Users\\Gabriel\\AppData\\Local\\Temp\\ipykernel_16784\\2950093071.py:93: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_trend'] = df[col].rolling(window=5).mean()\n",
      "C:\\Users\\Gabriel\\AppData\\Local\\Temp\\ipykernel_16784\\2950093071.py:93: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_trend'] = df[col].rolling(window=5).mean()\n",
      "C:\\Users\\Gabriel\\AppData\\Local\\Temp\\ipykernel_16784\\2950093071.py:93: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_trend'] = df[col].rolling(window=5).mean()\n",
      "C:\\Users\\Gabriel\\AppData\\Local\\Temp\\ipykernel_16784\\2950093071.py:93: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_trend'] = df[col].rolling(window=5).mean()\n",
      "C:\\Users\\Gabriel\\AppData\\Local\\Temp\\ipykernel_16784\\2950093071.py:93: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_trend'] = df[col].rolling(window=5).mean()\n",
      "C:\\Users\\Gabriel\\AppData\\Local\\Temp\\ipykernel_16784\\2950093071.py:93: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_trend'] = df[col].rolling(window=5).mean()\n",
      "C:\\Users\\Gabriel\\AppData\\Local\\Temp\\ipykernel_16784\\2950093071.py:93: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_trend'] = df[col].rolling(window=5).mean()\n",
      "C:\\Users\\Gabriel\\AppData\\Local\\Temp\\ipykernel_16784\\2950093071.py:93: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_trend'] = df[col].rolling(window=5).mean()\n",
      "C:\\Users\\Gabriel\\AppData\\Local\\Temp\\ipykernel_16784\\2950093071.py:93: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_trend'] = df[col].rolling(window=5).mean()\n",
      "C:\\Users\\Gabriel\\AppData\\Local\\Temp\\ipykernel_16784\\2950093071.py:93: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_trend'] = df[col].rolling(window=5).mean()\n",
      "C:\\Users\\Gabriel\\AppData\\Local\\Temp\\ipykernel_16784\\2950093071.py:93: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_trend'] = df[col].rolling(window=5).mean()\n",
      "C:\\Users\\Gabriel\\AppData\\Local\\Temp\\ipykernel_16784\\2950093071.py:93: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_trend'] = df[col].rolling(window=5).mean()\n",
      "C:\\Users\\Gabriel\\AppData\\Local\\Temp\\ipykernel_16784\\2950093071.py:93: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_trend'] = df[col].rolling(window=5).mean()\n",
      "C:\\Users\\Gabriel\\AppData\\Local\\Temp\\ipykernel_16784\\2950093071.py:93: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_trend'] = df[col].rolling(window=5).mean()\n",
      "C:\\Users\\Gabriel\\AppData\\Local\\Temp\\ipykernel_16784\\2950093071.py:93: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_trend'] = df[col].rolling(window=5).mean()\n",
      "C:\\Users\\Gabriel\\AppData\\Local\\Temp\\ipykernel_16784\\2950093071.py:93: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_trend'] = df[col].rolling(window=5).mean()\n",
      "C:\\Users\\Gabriel\\AppData\\Local\\Temp\\ipykernel_16784\\2950093071.py:93: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_trend'] = df[col].rolling(window=5).mean()\n",
      "C:\\Users\\Gabriel\\AppData\\Local\\Temp\\ipykernel_16784\\2950093071.py:93: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_trend'] = df[col].rolling(window=5).mean()\n",
      "C:\\Users\\Gabriel\\AppData\\Local\\Temp\\ipykernel_16784\\2950093071.py:93: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_trend'] = df[col].rolling(window=5).mean()\n",
      "C:\\Users\\Gabriel\\AppData\\Local\\Temp\\ipykernel_16784\\2950093071.py:93: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_trend'] = df[col].rolling(window=5).mean()\n",
      "C:\\Users\\Gabriel\\AppData\\Local\\Temp\\ipykernel_16784\\2950093071.py:93: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_trend'] = df[col].rolling(window=5).mean()\n",
      "C:\\Users\\Gabriel\\AppData\\Local\\Temp\\ipykernel_16784\\2950093071.py:93: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_trend'] = df[col].rolling(window=5).mean()\n",
      "C:\\Users\\Gabriel\\AppData\\Local\\Temp\\ipykernel_16784\\2950093071.py:93: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_trend'] = df[col].rolling(window=5).mean()\n",
      "C:\\Users\\Gabriel\\AppData\\Local\\Temp\\ipykernel_16784\\2950093071.py:93: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_trend'] = df[col].rolling(window=5).mean()\n",
      "C:\\Users\\Gabriel\\AppData\\Local\\Temp\\ipykernel_16784\\2950093071.py:93: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_trend'] = df[col].rolling(window=5).mean()\n",
      "C:\\Users\\Gabriel\\AppData\\Local\\Temp\\ipykernel_16784\\2950093071.py:93: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_trend'] = df[col].rolling(window=5).mean()\n",
      "C:\\Users\\Gabriel\\AppData\\Local\\Temp\\ipykernel_16784\\2950093071.py:93: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_trend'] = df[col].rolling(window=5).mean()\n",
      "C:\\Users\\Gabriel\\AppData\\Local\\Temp\\ipykernel_16784\\2950093071.py:93: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_trend'] = df[col].rolling(window=5).mean()\n",
      "C:\\Users\\Gabriel\\AppData\\Local\\Temp\\ipykernel_16784\\2950093071.py:93: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_trend'] = df[col].rolling(window=5).mean()\n",
      "C:\\Users\\Gabriel\\AppData\\Local\\Temp\\ipykernel_16784\\2950093071.py:93: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_trend'] = df[col].rolling(window=5).mean()\n",
      "C:\\Users\\Gabriel\\AppData\\Local\\Temp\\ipykernel_16784\\2950093071.py:93: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_trend'] = df[col].rolling(window=5).mean()\n",
      "C:\\Users\\Gabriel\\AppData\\Local\\Temp\\ipykernel_16784\\2950093071.py:93: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_trend'] = df[col].rolling(window=5).mean()\n",
      "C:\\Users\\Gabriel\\AppData\\Local\\Temp\\ipykernel_16784\\2950093071.py:93: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_trend'] = df[col].rolling(window=5).mean()\n",
      "C:\\Users\\Gabriel\\AppData\\Local\\Temp\\ipykernel_16784\\2950093071.py:93: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_trend'] = df[col].rolling(window=5).mean()\n",
      "C:\\Users\\Gabriel\\AppData\\Local\\Temp\\ipykernel_16784\\2950093071.py:93: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_trend'] = df[col].rolling(window=5).mean()\n",
      "C:\\Users\\Gabriel\\AppData\\Local\\Temp\\ipykernel_16784\\2950093071.py:93: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_trend'] = df[col].rolling(window=5).mean()\n",
      "C:\\Users\\Gabriel\\AppData\\Local\\Temp\\ipykernel_16784\\2950093071.py:93: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_trend'] = df[col].rolling(window=5).mean()\n",
      "C:\\Users\\Gabriel\\AppData\\Local\\Temp\\ipykernel_16784\\2950093071.py:93: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_trend'] = df[col].rolling(window=5).mean()\n",
      "C:\\Users\\Gabriel\\AppData\\Local\\Temp\\ipykernel_16784\\2950093071.py:93: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_trend'] = df[col].rolling(window=5).mean()\n",
      "C:\\Users\\Gabriel\\AppData\\Local\\Temp\\ipykernel_16784\\2950093071.py:93: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_trend'] = df[col].rolling(window=5).mean()\n",
      "C:\\Users\\Gabriel\\AppData\\Local\\Temp\\ipykernel_16784\\2950093071.py:93: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_trend'] = df[col].rolling(window=5).mean()\n",
      "C:\\Users\\Gabriel\\AppData\\Local\\Temp\\ipykernel_16784\\2950093071.py:93: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_trend'] = df[col].rolling(window=5).mean()\n",
      "C:\\Users\\Gabriel\\AppData\\Local\\Temp\\ipykernel_16784\\2950093071.py:93: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_trend'] = df[col].rolling(window=5).mean()\n",
      "C:\\Users\\Gabriel\\AppData\\Local\\Temp\\ipykernel_16784\\2950093071.py:93: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_trend'] = df[col].rolling(window=5).mean()\n",
      "C:\\Users\\Gabriel\\AppData\\Local\\Temp\\ipykernel_16784\\2950093071.py:93: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_trend'] = df[col].rolling(window=5).mean()\n",
      "C:\\Users\\Gabriel\\AppData\\Local\\Temp\\ipykernel_16784\\2950093071.py:93: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_trend'] = df[col].rolling(window=5).mean()\n",
      "C:\\Users\\Gabriel\\AppData\\Local\\Temp\\ipykernel_16784\\2950093071.py:93: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_trend'] = df[col].rolling(window=5).mean()\n",
      "C:\\Users\\Gabriel\\AppData\\Local\\Temp\\ipykernel_16784\\2950093071.py:93: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_trend'] = df[col].rolling(window=5).mean()\n",
      "C:\\Users\\Gabriel\\AppData\\Local\\Temp\\ipykernel_16784\\2950093071.py:93: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_trend'] = df[col].rolling(window=5).mean()\n",
      "C:\\Users\\Gabriel\\AppData\\Local\\Temp\\ipykernel_16784\\2950093071.py:93: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_trend'] = df[col].rolling(window=5).mean()\n",
      "C:\\Users\\Gabriel\\AppData\\Local\\Temp\\ipykernel_16784\\2950093071.py:93: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_trend'] = df[col].rolling(window=5).mean()\n",
      "C:\\Users\\Gabriel\\AppData\\Local\\Temp\\ipykernel_16784\\2950093071.py:93: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_trend'] = df[col].rolling(window=5).mean()\n",
      "C:\\Users\\Gabriel\\AppData\\Local\\Temp\\ipykernel_16784\\2950093071.py:93: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_trend'] = df[col].rolling(window=5).mean()\n",
      "C:\\Users\\Gabriel\\AppData\\Local\\Temp\\ipykernel_16784\\2950093071.py:93: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_trend'] = df[col].rolling(window=5).mean()\n",
      "C:\\Users\\Gabriel\\AppData\\Local\\Temp\\ipykernel_16784\\2950093071.py:93: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_trend'] = df[col].rolling(window=5).mean()\n",
      "C:\\Users\\Gabriel\\AppData\\Local\\Temp\\ipykernel_16784\\2950093071.py:93: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_trend'] = df[col].rolling(window=5).mean()\n",
      "C:\\Users\\Gabriel\\AppData\\Local\\Temp\\ipykernel_16784\\2950093071.py:93: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_trend'] = df[col].rolling(window=5).mean()\n",
      "C:\\Users\\Gabriel\\AppData\\Local\\Temp\\ipykernel_16784\\2950093071.py:93: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_trend'] = df[col].rolling(window=5).mean()\n",
      "C:\\Users\\Gabriel\\AppData\\Local\\Temp\\ipykernel_16784\\2950093071.py:93: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_trend'] = df[col].rolling(window=5).mean()\n",
      "C:\\Users\\Gabriel\\AppData\\Local\\Temp\\ipykernel_16784\\2950093071.py:93: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_trend'] = df[col].rolling(window=5).mean()\n",
      "C:\\Users\\Gabriel\\AppData\\Local\\Temp\\ipykernel_16784\\2950093071.py:93: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_trend'] = df[col].rolling(window=5).mean()\n",
      "C:\\Users\\Gabriel\\AppData\\Local\\Temp\\ipykernel_16784\\2950093071.py:93: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_trend'] = df[col].rolling(window=5).mean()\n",
      "C:\\Users\\Gabriel\\AppData\\Local\\Temp\\ipykernel_16784\\2950093071.py:93: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_trend'] = df[col].rolling(window=5).mean()\n",
      "C:\\Users\\Gabriel\\AppData\\Local\\Temp\\ipykernel_16784\\2950093071.py:93: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_trend'] = df[col].rolling(window=5).mean()\n",
      "C:\\Users\\Gabriel\\AppData\\Local\\Temp\\ipykernel_16784\\2950093071.py:93: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_trend'] = df[col].rolling(window=5).mean()\n",
      "C:\\Users\\Gabriel\\AppData\\Local\\Temp\\ipykernel_16784\\2950093071.py:93: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_trend'] = df[col].rolling(window=5).mean()\n",
      "C:\\Users\\Gabriel\\AppData\\Local\\Temp\\ipykernel_16784\\2950093071.py:93: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_trend'] = df[col].rolling(window=5).mean()\n",
      "C:\\Users\\Gabriel\\AppData\\Local\\Temp\\ipykernel_16784\\2950093071.py:93: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_trend'] = df[col].rolling(window=5).mean()\n",
      "C:\\Users\\Gabriel\\AppData\\Local\\Temp\\ipykernel_16784\\2950093071.py:93: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_trend'] = df[col].rolling(window=5).mean()\n",
      "C:\\Users\\Gabriel\\AppData\\Local\\Temp\\ipykernel_16784\\2950093071.py:93: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_trend'] = df[col].rolling(window=5).mean()\n",
      "C:\\Users\\Gabriel\\AppData\\Local\\Temp\\ipykernel_16784\\2950093071.py:93: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_trend'] = df[col].rolling(window=5).mean()\n",
      "C:\\Users\\Gabriel\\AppData\\Local\\Temp\\ipykernel_16784\\2950093071.py:93: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_trend'] = df[col].rolling(window=5).mean()\n",
      "C:\\Users\\Gabriel\\AppData\\Local\\Temp\\ipykernel_16784\\2950093071.py:93: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_trend'] = df[col].rolling(window=5).mean()\n",
      "C:\\Users\\Gabriel\\AppData\\Local\\Temp\\ipykernel_16784\\2950093071.py:93: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_trend'] = df[col].rolling(window=5).mean()\n",
      "C:\\Users\\Gabriel\\AppData\\Local\\Temp\\ipykernel_16784\\2950093071.py:93: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_trend'] = df[col].rolling(window=5).mean()\n",
      "C:\\Users\\Gabriel\\AppData\\Local\\Temp\\ipykernel_16784\\2950093071.py:93: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_trend'] = df[col].rolling(window=5).mean()\n",
      "C:\\Users\\Gabriel\\AppData\\Local\\Temp\\ipykernel_16784\\2950093071.py:93: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_trend'] = df[col].rolling(window=5).mean()\n",
      "C:\\Users\\Gabriel\\AppData\\Local\\Temp\\ipykernel_16784\\2950093071.py:93: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_trend'] = df[col].rolling(window=5).mean()\n",
      "C:\\Users\\Gabriel\\AppData\\Local\\Temp\\ipykernel_16784\\2950093071.py:93: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_trend'] = df[col].rolling(window=5).mean()\n",
      "C:\\Users\\Gabriel\\AppData\\Local\\Temp\\ipykernel_16784\\2950093071.py:93: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_trend'] = df[col].rolling(window=5).mean()\n",
      "C:\\Users\\Gabriel\\AppData\\Local\\Temp\\ipykernel_16784\\2950093071.py:93: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_trend'] = df[col].rolling(window=5).mean()\n",
      "C:\\Users\\Gabriel\\AppData\\Local\\Temp\\ipykernel_16784\\2950093071.py:93: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_trend'] = df[col].rolling(window=5).mean()\n",
      "C:\\Users\\Gabriel\\AppData\\Local\\Temp\\ipykernel_16784\\2950093071.py:93: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_trend'] = df[col].rolling(window=5).mean()\n",
      "C:\\Users\\Gabriel\\AppData\\Local\\Temp\\ipykernel_16784\\2950093071.py:93: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_trend'] = df[col].rolling(window=5).mean()\n",
      "C:\\Users\\Gabriel\\AppData\\Local\\Temp\\ipykernel_16784\\2950093071.py:93: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_trend'] = df[col].rolling(window=5).mean()\n",
      "C:\\Users\\Gabriel\\AppData\\Local\\Temp\\ipykernel_16784\\2950093071.py:93: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_trend'] = df[col].rolling(window=5).mean()\n",
      "C:\\Users\\Gabriel\\AppData\\Local\\Temp\\ipykernel_16784\\2950093071.py:93: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_trend'] = df[col].rolling(window=5).mean()\n",
      "C:\\Users\\Gabriel\\AppData\\Local\\Temp\\ipykernel_16784\\2950093071.py:93: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_trend'] = df[col].rolling(window=5).mean()\n",
      "C:\\Users\\Gabriel\\AppData\\Local\\Temp\\ipykernel_16784\\2950093071.py:93: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_trend'] = df[col].rolling(window=5).mean()\n",
      "C:\\Users\\Gabriel\\AppData\\Local\\Temp\\ipykernel_16784\\2950093071.py:93: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_trend'] = df[col].rolling(window=5).mean()\n",
      "C:\\Users\\Gabriel\\AppData\\Local\\Temp\\ipykernel_16784\\2950093071.py:93: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_trend'] = df[col].rolling(window=5).mean()\n",
      "C:\\Users\\Gabriel\\AppData\\Local\\Temp\\ipykernel_16784\\2950093071.py:93: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_trend'] = df[col].rolling(window=5).mean()\n",
      "C:\\Users\\Gabriel\\AppData\\Local\\Temp\\ipykernel_16784\\2950093071.py:93: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_trend'] = df[col].rolling(window=5).mean()\n",
      "C:\\Users\\Gabriel\\AppData\\Local\\Temp\\ipykernel_16784\\2950093071.py:93: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_trend'] = df[col].rolling(window=5).mean()\n",
      "C:\\Users\\Gabriel\\AppData\\Local\\Temp\\ipykernel_16784\\2950093071.py:93: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_trend'] = df[col].rolling(window=5).mean()\n",
      "C:\\Users\\Gabriel\\AppData\\Local\\Temp\\ipykernel_16784\\2950093071.py:93: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_trend'] = df[col].rolling(window=5).mean()\n",
      "C:\\Users\\Gabriel\\AppData\\Local\\Temp\\ipykernel_16784\\2950093071.py:93: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_trend'] = df[col].rolling(window=5).mean()\n",
      "C:\\Users\\Gabriel\\AppData\\Local\\Temp\\ipykernel_16784\\2950093071.py:93: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_trend'] = df[col].rolling(window=5).mean()\n",
      "C:\\Users\\Gabriel\\AppData\\Local\\Temp\\ipykernel_16784\\2950093071.py:93: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_trend'] = df[col].rolling(window=5).mean()\n",
      "C:\\Users\\Gabriel\\AppData\\Local\\Temp\\ipykernel_16784\\2950093071.py:93: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_trend'] = df[col].rolling(window=5).mean()\n",
      "C:\\Users\\Gabriel\\AppData\\Local\\Temp\\ipykernel_16784\\2950093071.py:93: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_trend'] = df[col].rolling(window=5).mean()\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Passing extra keyword arguments to IterativeImputer.fit is only supported if enable_metadata_routing=True, which you can set using `sklearn.set_config`. See the User Guide <https://scikit-learn.org/stable/metadata_routing.html> for more details. Extra parameters passed are: {'sample_weight'}",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[41]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m estado = \u001b[43mgraph\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmessages\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mHumanMessage\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontent\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mVerifique a existencia de nulos no dataset e lide com eles\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Gabriel\\OneDrive\\UFMG\\IC\\agenteiadp\\.venv\\Lib\\site-packages\\langgraph\\pregel\\main.py:3015\u001b[39m, in \u001b[36mPregel.invoke\u001b[39m\u001b[34m(self, input, config, context, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, durability, **kwargs)\u001b[39m\n\u001b[32m   3012\u001b[39m chunks: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any] | Any] = []\n\u001b[32m   3013\u001b[39m interrupts: \u001b[38;5;28mlist\u001b[39m[Interrupt] = []\n\u001b[32m-> \u001b[39m\u001b[32m3015\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3016\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   3017\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3018\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3019\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mupdates\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m   3020\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m   3021\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3022\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprint_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprint_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3023\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3024\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3025\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3026\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdurability\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdurability\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3027\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3028\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   3029\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\n\u001b[32m   3030\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m:\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Gabriel\\OneDrive\\UFMG\\IC\\agenteiadp\\.venv\\Lib\\site-packages\\langgraph\\pregel\\main.py:2642\u001b[39m, in \u001b[36mPregel.stream\u001b[39m\u001b[34m(self, input, config, context, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, durability, subgraphs, debug, **kwargs)\u001b[39m\n\u001b[32m   2640\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m task \u001b[38;5;129;01min\u001b[39;00m loop.match_cached_writes():\n\u001b[32m   2641\u001b[39m     loop.output_writes(task.id, task.writes, cached=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m-> \u001b[39m\u001b[32m2642\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrunner\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtick\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2643\u001b[39m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwrites\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2644\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstep_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2645\u001b[39m \u001b[43m    \u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[43m=\u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2646\u001b[39m \u001b[43m    \u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m=\u001b[49m\u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43maccept_push\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2647\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   2648\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# emit output\u001b[39;49;00m\n\u001b[32m   2649\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01myield from\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_output\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2650\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprint_mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubgraphs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mqueue\u001b[49m\u001b[43m.\u001b[49m\u001b[43mEmpty\u001b[49m\n\u001b[32m   2651\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2652\u001b[39m loop.after_tick()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Gabriel\\OneDrive\\UFMG\\IC\\agenteiadp\\.venv\\Lib\\site-packages\\langgraph\\pregel\\_runner.py:162\u001b[39m, in \u001b[36mPregelRunner.tick\u001b[39m\u001b[34m(self, tasks, reraise, timeout, retry_policy, get_waiter, schedule_task)\u001b[39m\n\u001b[32m    160\u001b[39m t = tasks[\u001b[32m0\u001b[39m]\n\u001b[32m    161\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m162\u001b[39m     \u001b[43mrun_with_retry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    163\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    164\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    165\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconfigurable\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    166\u001b[39m \u001b[43m            \u001b[49m\u001b[43mCONFIG_KEY_CALL\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    167\u001b[39m \u001b[43m                \u001b[49m\u001b[43m_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    168\u001b[39m \u001b[43m                \u001b[49m\u001b[43mweakref\u001b[49m\u001b[43m.\u001b[49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    169\u001b[39m \u001b[43m                \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    170\u001b[39m \u001b[43m                \u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m=\u001b[49m\u001b[43mweakref\u001b[49m\u001b[43m.\u001b[49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    171\u001b[39m \u001b[43m                \u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m=\u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    172\u001b[39m \u001b[43m                \u001b[49m\u001b[43msubmit\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msubmit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    173\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    174\u001b[39m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    175\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    176\u001b[39m     \u001b[38;5;28mself\u001b[39m.commit(t, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    177\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Gabriel\\OneDrive\\UFMG\\IC\\agenteiadp\\.venv\\Lib\\site-packages\\langgraph\\pregel\\_retry.py:42\u001b[39m, in \u001b[36mrun_with_retry\u001b[39m\u001b[34m(task, retry_policy, configurable)\u001b[39m\n\u001b[32m     40\u001b[39m     task.writes.clear()\n\u001b[32m     41\u001b[39m     \u001b[38;5;66;03m# run the task\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m42\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtask\u001b[49m\u001b[43m.\u001b[49m\u001b[43mproc\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m.\u001b[49m\u001b[43minput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     43\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ParentCommand \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m     44\u001b[39m     ns: \u001b[38;5;28mstr\u001b[39m = config[CONF][CONFIG_KEY_CHECKPOINT_NS]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Gabriel\\OneDrive\\UFMG\\IC\\agenteiadp\\.venv\\Lib\\site-packages\\langgraph\\_internal\\_runnable.py:657\u001b[39m, in \u001b[36mRunnableSeq.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    655\u001b[39m     \u001b[38;5;66;03m# run in context\u001b[39;00m\n\u001b[32m    656\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(config, run) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[32m--> \u001b[39m\u001b[32m657\u001b[39m         \u001b[38;5;28minput\u001b[39m = \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    658\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    659\u001b[39m     \u001b[38;5;28minput\u001b[39m = step.invoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Gabriel\\OneDrive\\UFMG\\IC\\agenteiadp\\.venv\\Lib\\site-packages\\langgraph\\_internal\\_runnable.py:401\u001b[39m, in \u001b[36mRunnableCallable.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    399\u001b[39m         run_manager.on_chain_end(ret)\n\u001b[32m    400\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m401\u001b[39m     ret = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    402\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.recurse \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret, Runnable):\n\u001b[32m    403\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m ret.invoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[39]\u001b[39m\u001b[32m, line 9\u001b[39m, in \u001b[36mchatbot\u001b[39m\u001b[34m(state)\u001b[39m\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mchatbot\u001b[39m(state: State):\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m: [\u001b[43magent\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmessages\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m]}\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Gabriel\\OneDrive\\UFMG\\IC\\agenteiadp\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py:165\u001b[39m, in \u001b[36mChain.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    162\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    163\u001b[39m     \u001b[38;5;28mself\u001b[39m._validate_inputs(inputs)\n\u001b[32m    164\u001b[39m     outputs = (\n\u001b[32m--> \u001b[39m\u001b[32m165\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    166\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[32m    167\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m._call(inputs)\n\u001b[32m    168\u001b[39m     )\n\u001b[32m    170\u001b[39m     final_outputs: \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any] = \u001b[38;5;28mself\u001b[39m.prep_outputs(\n\u001b[32m    171\u001b[39m         inputs,\n\u001b[32m    172\u001b[39m         outputs,\n\u001b[32m    173\u001b[39m         return_only_outputs,\n\u001b[32m    174\u001b[39m     )\n\u001b[32m    175\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Gabriel\\OneDrive\\UFMG\\IC\\agenteiadp\\.venv\\Lib\\site-packages\\langchain\\agents\\agent.py:1625\u001b[39m, in \u001b[36mAgentExecutor._call\u001b[39m\u001b[34m(self, inputs, run_manager)\u001b[39m\n\u001b[32m   1623\u001b[39m \u001b[38;5;66;03m# We now enter the agent loop (until it returns something).\u001b[39;00m\n\u001b[32m   1624\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m._should_continue(iterations, time_elapsed):\n\u001b[32m-> \u001b[39m\u001b[32m1625\u001b[39m     next_step_output = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_take_next_step\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1626\u001b[39m \u001b[43m        \u001b[49m\u001b[43mname_to_tool_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1627\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcolor_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1628\u001b[39m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1629\u001b[39m \u001b[43m        \u001b[49m\u001b[43mintermediate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1630\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1631\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1632\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(next_step_output, AgentFinish):\n\u001b[32m   1633\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._return(\n\u001b[32m   1634\u001b[39m             next_step_output,\n\u001b[32m   1635\u001b[39m             intermediate_steps,\n\u001b[32m   1636\u001b[39m             run_manager=run_manager,\n\u001b[32m   1637\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Gabriel\\OneDrive\\UFMG\\IC\\agenteiadp\\.venv\\Lib\\site-packages\\langchain\\agents\\agent.py:1325\u001b[39m, in \u001b[36mAgentExecutor._take_next_step\u001b[39m\u001b[34m(self, name_to_tool_map, color_mapping, inputs, intermediate_steps, run_manager)\u001b[39m\n\u001b[32m   1316\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_take_next_step\u001b[39m(\n\u001b[32m   1317\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1318\u001b[39m     name_to_tool_map: \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, BaseTool],\n\u001b[32m   (...)\u001b[39m\u001b[32m   1322\u001b[39m     run_manager: Optional[CallbackManagerForChainRun] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1323\u001b[39m ) -> Union[AgentFinish, \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mtuple\u001b[39m[AgentAction, \u001b[38;5;28mstr\u001b[39m]]]:\n\u001b[32m   1324\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._consume_next_step(\n\u001b[32m-> \u001b[39m\u001b[32m1325\u001b[39m         \u001b[38;5;28mlist\u001b[39m(\n\u001b[32m   1326\u001b[39m             \u001b[38;5;28mself\u001b[39m._iter_next_step(\n\u001b[32m   1327\u001b[39m                 name_to_tool_map,\n\u001b[32m   1328\u001b[39m                 color_mapping,\n\u001b[32m   1329\u001b[39m                 inputs,\n\u001b[32m   1330\u001b[39m                 intermediate_steps,\n\u001b[32m   1331\u001b[39m                 run_manager,\n\u001b[32m   1332\u001b[39m             ),\n\u001b[32m   1333\u001b[39m         ),\n\u001b[32m   1334\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Gabriel\\OneDrive\\UFMG\\IC\\agenteiadp\\.venv\\Lib\\site-packages\\langchain\\agents\\agent.py:1408\u001b[39m, in \u001b[36mAgentExecutor._iter_next_step\u001b[39m\u001b[34m(self, name_to_tool_map, color_mapping, inputs, intermediate_steps, run_manager)\u001b[39m\n\u001b[32m   1406\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m agent_action\n\u001b[32m   1407\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m agent_action \u001b[38;5;129;01min\u001b[39;00m actions:\n\u001b[32m-> \u001b[39m\u001b[32m1408\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_perform_agent_action\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1409\u001b[39m \u001b[43m        \u001b[49m\u001b[43mname_to_tool_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1410\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcolor_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1411\u001b[39m \u001b[43m        \u001b[49m\u001b[43magent_action\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1412\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1413\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Gabriel\\OneDrive\\UFMG\\IC\\agenteiadp\\.venv\\Lib\\site-packages\\langchain\\agents\\agent.py:1433\u001b[39m, in \u001b[36mAgentExecutor._perform_agent_action\u001b[39m\u001b[34m(self, name_to_tool_map, color_mapping, agent_action, run_manager)\u001b[39m\n\u001b[32m   1431\u001b[39m         tool_run_kwargs[\u001b[33m\"\u001b[39m\u001b[33mllm_prefix\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1432\u001b[39m     \u001b[38;5;66;03m# We then call the tool on the tool input to get an observation\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1433\u001b[39m     observation = \u001b[43mtool\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1434\u001b[39m \u001b[43m        \u001b[49m\u001b[43magent_action\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtool_input\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1435\u001b[39m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1436\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcolor\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcolor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1437\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_child\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1438\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mtool_run_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1439\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1440\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1441\u001b[39m     tool_run_kwargs = \u001b[38;5;28mself\u001b[39m._action_agent.tool_run_logging_kwargs()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Gabriel\\OneDrive\\UFMG\\IC\\agenteiadp\\.venv\\Lib\\site-packages\\langchain_core\\tools\\base.py:883\u001b[39m, in \u001b[36mBaseTool.run\u001b[39m\u001b[34m(self, tool_input, verbose, start_color, color, callbacks, tags, metadata, run_name, run_id, config, tool_call_id, **kwargs)\u001b[39m\n\u001b[32m    881\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m error_to_raise:\n\u001b[32m    882\u001b[39m     run_manager.on_tool_error(error_to_raise)\n\u001b[32m--> \u001b[39m\u001b[32m883\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m error_to_raise\n\u001b[32m    884\u001b[39m output = _format_output(content, artifact, tool_call_id, \u001b[38;5;28mself\u001b[39m.name, status)\n\u001b[32m    885\u001b[39m run_manager.on_tool_end(output, color=color, name=\u001b[38;5;28mself\u001b[39m.name, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Gabriel\\OneDrive\\UFMG\\IC\\agenteiadp\\.venv\\Lib\\site-packages\\langchain_core\\tools\\base.py:852\u001b[39m, in \u001b[36mBaseTool.run\u001b[39m\u001b[34m(self, tool_input, verbose, start_color, color, callbacks, tags, metadata, run_name, run_id, config, tool_call_id, **kwargs)\u001b[39m\n\u001b[32m    850\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m config_param := _get_runnable_config_param(\u001b[38;5;28mself\u001b[39m._run):\n\u001b[32m    851\u001b[39m         tool_kwargs |= {config_param: config}\n\u001b[32m--> \u001b[39m\u001b[32m852\u001b[39m     response = \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43mtool_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mtool_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    853\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.response_format == \u001b[33m\"\u001b[39m\u001b[33mcontent_and_artifact\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    854\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response, \u001b[38;5;28mtuple\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(response) != \u001b[32m2\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Gabriel\\OneDrive\\UFMG\\IC\\agenteiadp\\.venv\\Lib\\site-packages\\langchain_core\\tools\\structured.py:93\u001b[39m, in \u001b[36mStructuredTool._run\u001b[39m\u001b[34m(self, config, run_manager, *args, **kwargs)\u001b[39m\n\u001b[32m     91\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m config_param := _get_runnable_config_param(\u001b[38;5;28mself\u001b[39m.func):\n\u001b[32m     92\u001b[39m         kwargs[config_param] = config\n\u001b[32m---> \u001b[39m\u001b[32m93\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     94\u001b[39m msg = \u001b[33m\"\u001b[39m\u001b[33mStructuredTool does not support sync invocation.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     95\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(msg)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[37]\u001b[39m\u001b[32m, line 100\u001b[39m, in \u001b[36mimputacao_stmw\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     93\u001b[39m     df[\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcol\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m_trend\u001b[39m\u001b[33m'\u001b[39m] = df[col].rolling(window=\u001b[32m5\u001b[39m).mean()\n\u001b[32m     95\u001b[39m imputer = IterativeImputer(\n\u001b[32m     96\u001b[39m     estimator=RandomForestRegressor(n_estimators=\u001b[32m100\u001b[39m),\n\u001b[32m     97\u001b[39m     max_iter=\u001b[32m15\u001b[39m,\n\u001b[32m     98\u001b[39m     random_state=\u001b[32m42\u001b[39m\n\u001b[32m     99\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m100\u001b[39m df.iloc[:, :] = \u001b[43mimputer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtime_weights\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    101\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mSTMW aplicado. Temporalidade ponderada.\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Gabriel\\OneDrive\\UFMG\\IC\\agenteiadp\\.venv\\Lib\\site-packages\\sklearn\\utils\\_set_output.py:316\u001b[39m, in \u001b[36m_wrap_method_output.<locals>.wrapped\u001b[39m\u001b[34m(self, X, *args, **kwargs)\u001b[39m\n\u001b[32m    314\u001b[39m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[32m    315\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, *args, **kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m316\u001b[39m     data_to_wrap = \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    317\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[32m    318\u001b[39m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[32m    319\u001b[39m         return_tuple = (\n\u001b[32m    320\u001b[39m             _wrap_data_with_container(method, data_to_wrap[\u001b[32m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[32m    321\u001b[39m             *data_to_wrap[\u001b[32m1\u001b[39m:],\n\u001b[32m    322\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Gabriel\\OneDrive\\UFMG\\IC\\agenteiadp\\.venv\\Lib\\site-packages\\sklearn\\base.py:1365\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1358\u001b[39m     estimator._validate_params()\n\u001b[32m   1360\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1361\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1362\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1363\u001b[39m     )\n\u001b[32m   1364\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1365\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Gabriel\\OneDrive\\UFMG\\IC\\agenteiadp\\.venv\\Lib\\site-packages\\sklearn\\impute\\_iterative.py:778\u001b[39m, in \u001b[36mIterativeImputer.fit_transform\u001b[39m\u001b[34m(self, X, y, **params)\u001b[39m\n\u001b[32m    747\u001b[39m \u001b[38;5;129m@_fit_context\u001b[39m(\n\u001b[32m    748\u001b[39m     \u001b[38;5;66;03m# IterativeImputer.estimator is not validated yet\u001b[39;00m\n\u001b[32m    749\u001b[39m     prefer_skip_nested_validation=\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    750\u001b[39m )\n\u001b[32m    751\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfit_transform\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y=\u001b[38;5;28;01mNone\u001b[39;00m, **params):\n\u001b[32m    752\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Fit the imputer on `X` and return the transformed `X`.\u001b[39;00m\n\u001b[32m    753\u001b[39m \n\u001b[32m    754\u001b[39m \u001b[33;03m    Parameters\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    776\u001b[39m \u001b[33;03m        The imputed input data.\u001b[39;00m\n\u001b[32m    777\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m778\u001b[39m     \u001b[43m_raise_for_params\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfit\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    780\u001b[39m     routed_params = process_routing(\n\u001b[32m    781\u001b[39m         \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    782\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mfit\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    783\u001b[39m         **params,\n\u001b[32m    784\u001b[39m     )\n\u001b[32m    786\u001b[39m     \u001b[38;5;28mself\u001b[39m.random_state_ = \u001b[38;5;28mgetattr\u001b[39m(\n\u001b[32m    787\u001b[39m         \u001b[38;5;28mself\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mrandom_state_\u001b[39m\u001b[33m\"\u001b[39m, check_random_state(\u001b[38;5;28mself\u001b[39m.random_state)\n\u001b[32m    788\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Gabriel\\OneDrive\\UFMG\\IC\\agenteiadp\\.venv\\Lib\\site-packages\\sklearn\\utils\\_metadata_requests.py:186\u001b[39m, in \u001b[36m_raise_for_params\u001b[39m\u001b[34m(params, owner, method, allow)\u001b[39m\n\u001b[32m    183\u001b[39m allow = allow \u001b[38;5;28;01mif\u001b[39;00m allow \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m {}\n\u001b[32m    185\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _routing_enabled() \u001b[38;5;129;01mand\u001b[39;00m (params.keys() - allow):\n\u001b[32m--> \u001b[39m\u001b[32m186\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    187\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mPassing extra keyword arguments to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcaller\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m is only supported if\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    188\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m enable_metadata_routing=True, which you can set using\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    189\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m `sklearn.set_config`. See the User Guide\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    190\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m <https://scikit-learn.org/stable/metadata_routing.html> for more\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    191\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m details. Extra parameters passed are: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mset\u001b[39m(params)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    192\u001b[39m     )\n",
      "\u001b[31mValueError\u001b[39m: Passing extra keyword arguments to IterativeImputer.fit is only supported if enable_metadata_routing=True, which you can set using `sklearn.set_config`. See the User Guide <https://scikit-learn.org/stable/metadata_routing.html> for more details. Extra parameters passed are: {'sample_weight'}",
      "During task with name 'chatbot' and id 'cbda5448-9322-d3db-704f-9bb7127040e2'"
     ]
    }
   ],
   "source": [
    "estado = graph.invoke({\"messages\": [HumanMessage(content=\"Verifique a existencia de nulos no dataset e lide com eles\")]}, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bd784ecd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'input': [HumanMessage(content='Me forneça uma informação interessante sobre o dataset', additional_kwargs={}, response_metadata={})],\n",
       "  'output': \"A coluna '313344' tem uma média de 120.40, um desvio padrão de 76.84 e não possui valores nulos, apresentando uma grande variabilidade nos dados.\",\n",
       "  'intermediate_steps': [(AgentAction(tool='get_column_names', tool_input='None', log='Thought: Para fornecer uma informação interessante sobre o dataset, primeiro preciso entender a estrutura e o conteúdo do dataset. Vou começar obtendo os nomes das colunas.\\n\\nAction: get_column_names\\nAction Input: None'),\n",
       "    \"['timestamp', '313344', '313349', '313438', '313450', '313487', '313493', '313512', '313551', '313552', '317752', '313658', '317814', '317815', '317842', '317843', '317852', '317853', '315804', '317861', '317862', '313772', '317869', '315822', '317870', '315823', '315824', '315826', '315827', '315828', '315825', '315830', '315831', '315833', '315834', '315835', '317884', '317885', '315836', '315837', '315838', '315841', '315842', '315839', '315843', '315846', '315847', '317895', '315849', '315850', '317896', '315852', '315853', '317902', '317903', '315854', '315855', '315856', '315858', '315860', '315861', '317909', '317910', '315857', '315866', '315867', '315872', '315873', '315874', '315875', '315879', '315880', '315882', '315883', '317933', '315886', '315887', '317934', '315891', '315892', '315894', '315895', '313846', '317947', '313852', '315900', '317948', '315901', '315904', '315903', '315907', '317956', '315908', '315910', '315911', '317960', '315913', '315914', '315915', '317974', '315927', '315938', '317998', '315955', '315969', '318022', '318028', '318029', '315982', '318035', '318036', '315993', '311903', '313951', '316001', '313956', '318053', '318052', '316009', '316018', '316019', '311930', '313979', '318076', '318077', '316032', '316045', '318102', '314013', '316063', '316064', '318113', '316073', '316074', '314025', '318126', '316084', '316085', '314036', '318135', '314042', '318142', '312010', '316114', '316118', '316129', '318179', '318180', '314121', '318218', '316174', '318236', '312098', '314147', '312103', '314157', '314165', '312132', '312133', '312134', '318282', '312139', '314217', '316271', '314230', '316279', '316280', '316281', '312188', '314241', '314248', '318354', '316314', '312220', '318366', '316328', '312233', '312236', '318383', '318401', '312264', '318412', '316364', '318421', '318432', '316387', '316388', '318443', '316399', '316400', '318451', '316414', '314371', '312326', '314379', '316429', '318484', '316438', '312343', '312346', '318493', '316451', '314419', '312382', '318528', '314433', '312386', '312388', '318540', '314446', '318550', '318551', '314460', '312420', '312421', '312422', '318565', '318566', '312425', '318575', '318576', '314485', '312439', '318586', '314491', '318593', '314501', '318599', '318611', '318612', '318620', '318626', '318632', '318636', '314548', '318649', '318650', '314559', '318656', '312513', '312514', '312517', '312520', '318665', '318666', '312523', '312525', '312527', '318674', '312530', '318680', '314598', '312562', '312564', '312566', '318711', '314617', '312570', '318721', '314625', '318736', '318742', '318744', '314652', '318753', '318764', '314668', '318772', '318773', '318775', '314681', '314689', '318787', '318788', '312648', '314697', '314698', '312651', '318800', '318801', '314711', '314712', '318815', '318816', '314730', '318832', '312689', '312694', '318844', '312745', '312757', '312771', '312782', '312804', '312807', '314876', '314877', '314886', '314899', '312852', '312854', '312856', '312857', '312858', '314909', '312865', '314923', '314936', '312895', '312896', '312898', '312900', '314955', '314968', '314982', '312940', '312942', '312944', '314994', '312946', '315006', '317064', '315017', '315030', '317081', '317088', '315042', '313000', '313003', '313005', '315054', '313010', '315060', '313035', '313037', '317139', '317141', '317143', '317146', '313055', '317157', '317166', '317168', '317171', '313080', '313082', '313111', '313114', '313132', '313144', '313159', '313166', '313172', '313178', '313184', '313190', '313197', '313204', '313339']\"),\n",
       "   (AgentAction(tool='summary_statistics', tool_input='313344', log=\"O dataset contém uma coluna 'timestamp' e várias outras colunas numéricas. Para fornecer uma informação interessante, vou calcular as estatísticas descritivas de uma das colunas numéricas e verificar se há valores nulos.\\n\\nAction: summary_statistics\\nAction Input: 313344\"),\n",
       "    'count    26208.000000\\nmean       120.401748\\nstd         76.841761\\nmin          0.000000\\n25%         46.000000\\n50%        128.000000\\n75%        176.000000\\nmax        339.000000'),\n",
       "   (AgentAction(tool='check_missing_values', tool_input='313344', log=\"A coluna '313344' tem uma média de aproximadamente 120.40 e um desvio padrão de aproximadamente 76.84. Isso sugere que os valores nessa coluna variam significativamente. Além disso, o valor mínimo é 0 e o máximo é 339, o que indica uma grande amplitude nos dados.\\n\\nVou verificar se há valores nulos nessa coluna.\\n\\nAction: check_missing_values\\nAction Input: 313344\"),\n",
       "    \"A coluna '313344' tem 0 valores faltantes.\")]}]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estado[\"messages\"]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agenteiadp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
